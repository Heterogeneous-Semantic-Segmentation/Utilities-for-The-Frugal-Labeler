{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from unet_model import unet,dice_coef,dice_coef_loss\n",
    "from data import adjustData,trainGenerator,testGenerator,labelVisualize,saveResult\n",
    "from tensorflow.keras.callbacks import  EarlyStopping, ReduceLROnPlateau \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "X_test = []\n",
    "for filepath in os.listdir('../data/test_images/ventral_samples_R0004'):\n",
    "    image = Image.open('../data/test_images/ventral_samples_R0004/'+filepath)\n",
    "    image = image.resize((256, 256))\n",
    "    # convert image to numpy array\n",
    "    data = np.asarray(image)\n",
    "    data = data/255.\n",
    "    X_test.append(data)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = []\n",
    "for filepath in os.listdir('../data/test_images/ventral_mask_atrium_R0004_binary'):\n",
    "    image = Image.open('../data/test_images/ventral_mask_atrium_R0004_binary/'+filepath).convert('L')\n",
    "    image = image.resize((256, 256))\n",
    "    data = np.asarray(image).reshape(256,256,1)\n",
    "    data = data/255.\n",
    "    Y_test.append(data)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 400\n",
    "iterations_per_epoch = 300\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.3,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.1,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "train_generator = trainGenerator(batch_size,'../data/train_images','ventral_samples','ventral_mask_atrium_binary',data_gen_args,image_color_mode='rgb')\n",
    "val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-7d592abd7be6>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 565 images belonging to 1 classes.\n",
      "Found 565 images belonging to 1 classes.\n",
      "Epoch 1/400\n",
      "  2/300 [..............................] - ETA: 1:06 - loss: 0.9676 - dice_coef: 0.0324 - accuracy: 0.9847WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1336s vs `on_train_batch_end` time: 0.3152s). Check your callbacks.\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.7395 - dice_coef: 0.2604 - accuracy: 0.9838\n",
      "Epoch 00001: val_loss improved from inf to 0.75044, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 139s 465ms/step - loss: 0.7395 - dice_coef: 0.2604 - accuracy: 0.9838 - val_loss: 0.7504 - val_dice_coef: 0.2532 - val_accuracy: 0.9778\n",
      "Epoch 2/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.5790 - dice_coef: 0.4213 - accuracy: 0.9867\n",
      "Epoch 00002: val_loss improved from 0.75044 to 0.73347, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 455ms/step - loss: 0.5790 - dice_coef: 0.4213 - accuracy: 0.9867 - val_loss: 0.7335 - val_dice_coef: 0.2693 - val_accuracy: 0.9754\n",
      "Epoch 3/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4929 - dice_coef: 0.5070 - accuracy: 0.9920\n",
      "Epoch 00003: val_loss improved from 0.73347 to 0.71206, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.4929 - dice_coef: 0.5070 - accuracy: 0.9920 - val_loss: 0.7121 - val_dice_coef: 0.2904 - val_accuracy: 0.9820\n",
      "Epoch 4/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4451 - dice_coef: 0.5548 - accuracy: 0.9947\n",
      "Epoch 00004: val_loss did not improve from 0.71206\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.4451 - dice_coef: 0.5548 - accuracy: 0.9947 - val_loss: 0.8412 - val_dice_coef: 0.1586 - val_accuracy: 0.9852\n",
      "Epoch 5/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4221 - dice_coef: 0.5780 - accuracy: 0.9957\n",
      "Epoch 00005: val_loss improved from 0.71206 to 0.69374, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.4221 - dice_coef: 0.5780 - accuracy: 0.9957 - val_loss: 0.6937 - val_dice_coef: 0.3050 - val_accuracy: 0.9870\n",
      "Epoch 6/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4126 - dice_coef: 0.5875 - accuracy: 0.9960\n",
      "Epoch 00006: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.4126 - dice_coef: 0.5875 - accuracy: 0.9960 - val_loss: 0.8115 - val_dice_coef: 0.1922 - val_accuracy: 0.9858\n",
      "Epoch 7/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4055 - dice_coef: 0.5946 - accuracy: 0.9963\n",
      "Epoch 00007: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.4055 - dice_coef: 0.5946 - accuracy: 0.9963 - val_loss: 0.7308 - val_dice_coef: 0.2717 - val_accuracy: 0.9864\n",
      "Epoch 8/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4020 - dice_coef: 0.5980 - accuracy: 0.9964\n",
      "Epoch 00008: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.4020 - dice_coef: 0.5980 - accuracy: 0.9964 - val_loss: 0.8472 - val_dice_coef: 0.1561 - val_accuracy: 0.9858\n",
      "Epoch 9/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3980 - dice_coef: 0.6019 - accuracy: 0.9965\n",
      "Epoch 00009: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3980 - dice_coef: 0.6019 - accuracy: 0.9965 - val_loss: 0.7326 - val_dice_coef: 0.2694 - val_accuracy: 0.9862\n",
      "Epoch 10/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3971 - dice_coef: 0.6028 - accuracy: 0.9965\n",
      "Epoch 00010: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3971 - dice_coef: 0.6028 - accuracy: 0.9965 - val_loss: 0.7367 - val_dice_coef: 0.2607 - val_accuracy: 0.9862\n",
      "Epoch 11/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3953 - dice_coef: 0.6048 - accuracy: 0.9966\n",
      "Epoch 00011: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3953 - dice_coef: 0.6048 - accuracy: 0.9966 - val_loss: 0.8742 - val_dice_coef: 0.1240 - val_accuracy: 0.9856\n",
      "Epoch 12/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3933 - dice_coef: 0.6067 - accuracy: 0.9967\n",
      "Epoch 00012: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3933 - dice_coef: 0.6067 - accuracy: 0.9967 - val_loss: 0.7414 - val_dice_coef: 0.2593 - val_accuracy: 0.9863\n",
      "Epoch 13/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3898 - dice_coef: 0.6099 - accuracy: 0.9967\n",
      "Epoch 00013: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3898 - dice_coef: 0.6099 - accuracy: 0.9967 - val_loss: 0.7462 - val_dice_coef: 0.2537 - val_accuracy: 0.9839\n",
      "Epoch 14/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3909 - dice_coef: 0.6091 - accuracy: 0.9967\n",
      "Epoch 00014: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3909 - dice_coef: 0.6091 - accuracy: 0.9967 - val_loss: 0.8010 - val_dice_coef: 0.1971 - val_accuracy: 0.9858\n",
      "Epoch 15/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3882 - dice_coef: 0.6119 - accuracy: 0.9967\n",
      "Epoch 00015: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3882 - dice_coef: 0.6119 - accuracy: 0.9967 - val_loss: 0.7315 - val_dice_coef: 0.2698 - val_accuracy: 0.9858\n",
      "Epoch 16/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3866 - dice_coef: 0.6136 - accuracy: 0.9968\n",
      "Epoch 00016: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3866 - dice_coef: 0.6136 - accuracy: 0.9968 - val_loss: 0.8082 - val_dice_coef: 0.1937 - val_accuracy: 0.9861\n",
      "Epoch 17/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3850 - dice_coef: 0.6151 - accuracy: 0.9968\n",
      "Epoch 00017: val_loss did not improve from 0.69374\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3850 - dice_coef: 0.6151 - accuracy: 0.9968 - val_loss: 0.7428 - val_dice_coef: 0.2550 - val_accuracy: 0.9867\n",
      "Epoch 18/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3847 - dice_coef: 0.6153 - accuracy: 0.9969\n",
      "Epoch 00018: val_loss improved from 0.69374 to 0.69334, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.3847 - dice_coef: 0.6153 - accuracy: 0.9969 - val_loss: 0.6933 - val_dice_coef: 0.3069 - val_accuracy: 0.9873\n",
      "Epoch 19/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3829 - dice_coef: 0.6171 - accuracy: 0.9969\n",
      "Epoch 00019: val_loss did not improve from 0.69334\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3829 - dice_coef: 0.6171 - accuracy: 0.9969 - val_loss: 0.7934 - val_dice_coef: 0.2089 - val_accuracy: 0.9866\n",
      "Epoch 20/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3815 - dice_coef: 0.6182 - accuracy: 0.9969\n",
      "Epoch 00020: val_loss did not improve from 0.69334\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3815 - dice_coef: 0.6182 - accuracy: 0.9969 - val_loss: 0.6956 - val_dice_coef: 0.3113 - val_accuracy: 0.9873\n",
      "Epoch 21/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3816 - dice_coef: 0.6184 - accuracy: 0.9969\n",
      "Epoch 00021: val_loss improved from 0.69334 to 0.67633, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.3816 - dice_coef: 0.6184 - accuracy: 0.9969 - val_loss: 0.6763 - val_dice_coef: 0.3207 - val_accuracy: 0.9871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3798 - dice_coef: 0.6202 - accuracy: 0.9970\n",
      "Epoch 00022: val_loss did not improve from 0.67633\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3798 - dice_coef: 0.6202 - accuracy: 0.9970 - val_loss: 0.7627 - val_dice_coef: 0.2365 - val_accuracy: 0.9869\n",
      "Epoch 23/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3804 - dice_coef: 0.6197 - accuracy: 0.9969\n",
      "Epoch 00023: val_loss did not improve from 0.67633\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3804 - dice_coef: 0.6197 - accuracy: 0.9969 - val_loss: 0.8465 - val_dice_coef: 0.1515 - val_accuracy: 0.9862\n",
      "Epoch 24/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3777 - dice_coef: 0.6223 - accuracy: 0.9970\n",
      "Epoch 00024: val_loss improved from 0.67633 to 0.58855, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.3777 - dice_coef: 0.6223 - accuracy: 0.9970 - val_loss: 0.5886 - val_dice_coef: 0.4111 - val_accuracy: 0.9876\n",
      "Epoch 25/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3785 - dice_coef: 0.6215 - accuracy: 0.9969\n",
      "Epoch 00025: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3785 - dice_coef: 0.6215 - accuracy: 0.9969 - val_loss: 0.6686 - val_dice_coef: 0.3269 - val_accuracy: 0.9877\n",
      "Epoch 26/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3756 - dice_coef: 0.6244 - accuracy: 0.9970\n",
      "Epoch 00026: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3756 - dice_coef: 0.6244 - accuracy: 0.9970 - val_loss: 0.6242 - val_dice_coef: 0.3742 - val_accuracy: 0.9879\n",
      "Epoch 27/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3743 - dice_coef: 0.6254 - accuracy: 0.9970\n",
      "Epoch 00027: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3743 - dice_coef: 0.6254 - accuracy: 0.9970 - val_loss: 0.8379 - val_dice_coef: 0.1595 - val_accuracy: 0.9862\n",
      "Epoch 28/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3726 - dice_coef: 0.6274 - accuracy: 0.9971\n",
      "Epoch 00028: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3726 - dice_coef: 0.6274 - accuracy: 0.9971 - val_loss: 0.7384 - val_dice_coef: 0.2605 - val_accuracy: 0.9871\n",
      "Epoch 29/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3726 - dice_coef: 0.6275 - accuracy: 0.9971\n",
      "Epoch 00029: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3726 - dice_coef: 0.6275 - accuracy: 0.9971 - val_loss: 0.8126 - val_dice_coef: 0.1860 - val_accuracy: 0.9855\n",
      "Epoch 30/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3718 - dice_coef: 0.6283 - accuracy: 0.9971\n",
      "Epoch 00030: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3718 - dice_coef: 0.6283 - accuracy: 0.9971 - val_loss: 0.7731 - val_dice_coef: 0.2231 - val_accuracy: 0.9866\n",
      "Epoch 31/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3704 - dice_coef: 0.6296 - accuracy: 0.9971\n",
      "Epoch 00031: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3704 - dice_coef: 0.6296 - accuracy: 0.9971 - val_loss: 0.8780 - val_dice_coef: 0.1238 - val_accuracy: 0.9859\n",
      "Epoch 32/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3698 - dice_coef: 0.6304 - accuracy: 0.9971\n",
      "Epoch 00032: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3698 - dice_coef: 0.6304 - accuracy: 0.9971 - val_loss: 0.5907 - val_dice_coef: 0.4054 - val_accuracy: 0.9891\n",
      "Epoch 33/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3696 - dice_coef: 0.6305 - accuracy: 0.9971\n",
      "Epoch 00033: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3696 - dice_coef: 0.6305 - accuracy: 0.9971 - val_loss: 0.6348 - val_dice_coef: 0.3656 - val_accuracy: 0.9826\n",
      "Epoch 34/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3679 - dice_coef: 0.6321 - accuracy: 0.9971\n",
      "Epoch 00034: val_loss did not improve from 0.58855\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3679 - dice_coef: 0.6321 - accuracy: 0.9971 - val_loss: 0.7005 - val_dice_coef: 0.3001 - val_accuracy: 0.9879\n",
      "Epoch 35/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3681 - dice_coef: 0.6318 - accuracy: 0.9971\n",
      "Epoch 00035: val_loss improved from 0.58855 to 0.58268, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 455ms/step - loss: 0.3681 - dice_coef: 0.6318 - accuracy: 0.9971 - val_loss: 0.5827 - val_dice_coef: 0.4139 - val_accuracy: 0.9888\n",
      "Epoch 36/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3653 - dice_coef: 0.6346 - accuracy: 0.9972\n",
      "Epoch 00036: val_loss did not improve from 0.58268\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3653 - dice_coef: 0.6346 - accuracy: 0.9972 - val_loss: 0.6200 - val_dice_coef: 0.3825 - val_accuracy: 0.9884\n",
      "Epoch 37/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3661 - dice_coef: 0.6338 - accuracy: 0.9971\n",
      "Epoch 00037: val_loss did not improve from 0.58268\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3661 - dice_coef: 0.6338 - accuracy: 0.9971 - val_loss: 0.6954 - val_dice_coef: 0.3042 - val_accuracy: 0.9876\n",
      "Epoch 38/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3651 - dice_coef: 0.6349 - accuracy: 0.9972\n",
      "Epoch 00038: val_loss did not improve from 0.58268\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3651 - dice_coef: 0.6349 - accuracy: 0.9972 - val_loss: 0.6615 - val_dice_coef: 0.3329 - val_accuracy: 0.9879\n",
      "Epoch 39/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3643 - dice_coef: 0.6356 - accuracy: 0.9972\n",
      "Epoch 00039: val_loss did not improve from 0.58268\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3643 - dice_coef: 0.6356 - accuracy: 0.9972 - val_loss: 0.6673 - val_dice_coef: 0.3302 - val_accuracy: 0.9880\n",
      "Epoch 40/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3631 - dice_coef: 0.6370 - accuracy: 0.9972\n",
      "Epoch 00040: val_loss did not improve from 0.58268\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3631 - dice_coef: 0.6370 - accuracy: 0.9972 - val_loss: 0.6461 - val_dice_coef: 0.3563 - val_accuracy: 0.9882\n",
      "Epoch 41/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3623 - dice_coef: 0.6378 - accuracy: 0.9972\n",
      "Epoch 00041: val_loss improved from 0.58268 to 0.56243, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.3623 - dice_coef: 0.6378 - accuracy: 0.9972 - val_loss: 0.5624 - val_dice_coef: 0.4396 - val_accuracy: 0.9889\n",
      "Epoch 42/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3629 - dice_coef: 0.6372 - accuracy: 0.9972\n",
      "Epoch 00042: val_loss improved from 0.56243 to 0.55190, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 455ms/step - loss: 0.3629 - dice_coef: 0.6372 - accuracy: 0.9972 - val_loss: 0.5519 - val_dice_coef: 0.4503 - val_accuracy: 0.9897\n",
      "Epoch 43/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3607 - dice_coef: 0.6390 - accuracy: 0.9972\n",
      "Epoch 00043: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3607 - dice_coef: 0.6390 - accuracy: 0.9972 - val_loss: 0.5982 - val_dice_coef: 0.4053 - val_accuracy: 0.9891\n",
      "Epoch 44/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3597 - dice_coef: 0.6404 - accuracy: 0.9972\n",
      "Epoch 00044: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3597 - dice_coef: 0.6404 - accuracy: 0.9972 - val_loss: 0.6450 - val_dice_coef: 0.3559 - val_accuracy: 0.9885\n",
      "Epoch 45/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 0.3586 - dice_coef: 0.6415 - accuracy: 0.9973\n",
      "Epoch 00045: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3586 - dice_coef: 0.6415 - accuracy: 0.9973 - val_loss: 0.5744 - val_dice_coef: 0.4270 - val_accuracy: 0.9889\n",
      "Epoch 46/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3582 - dice_coef: 0.6419 - accuracy: 0.9973\n",
      "Epoch 00046: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3582 - dice_coef: 0.6419 - accuracy: 0.9973 - val_loss: 0.5590 - val_dice_coef: 0.4424 - val_accuracy: 0.9896\n",
      "Epoch 47/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3573 - dice_coef: 0.6428 - accuracy: 0.9973\n",
      "Epoch 00047: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3573 - dice_coef: 0.6428 - accuracy: 0.9973 - val_loss: 0.6545 - val_dice_coef: 0.3495 - val_accuracy: 0.9883\n",
      "Epoch 48/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3571 - dice_coef: 0.6430 - accuracy: 0.9973\n",
      "Epoch 00048: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3571 - dice_coef: 0.6430 - accuracy: 0.9973 - val_loss: 0.6460 - val_dice_coef: 0.3567 - val_accuracy: 0.9883\n",
      "Epoch 49/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3557 - dice_coef: 0.6443 - accuracy: 0.9973\n",
      "Epoch 00049: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3557 - dice_coef: 0.6443 - accuracy: 0.9973 - val_loss: 0.7115 - val_dice_coef: 0.2885 - val_accuracy: 0.9872\n",
      "Epoch 50/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3564 - dice_coef: 0.6433 - accuracy: 0.9973\n",
      "Epoch 00050: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3564 - dice_coef: 0.6433 - accuracy: 0.9973 - val_loss: 0.6633 - val_dice_coef: 0.3363 - val_accuracy: 0.9869\n",
      "Epoch 51/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3554 - dice_coef: 0.6447 - accuracy: 0.9973\n",
      "Epoch 00051: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3554 - dice_coef: 0.6447 - accuracy: 0.9973 - val_loss: 0.6233 - val_dice_coef: 0.3715 - val_accuracy: 0.9886\n",
      "Epoch 52/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3532 - dice_coef: 0.6464 - accuracy: 0.9973\n",
      "Epoch 00052: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3532 - dice_coef: 0.6464 - accuracy: 0.9973 - val_loss: 0.7603 - val_dice_coef: 0.2364 - val_accuracy: 0.9867\n",
      "Epoch 53/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3533 - dice_coef: 0.6468 - accuracy: 0.9973\n",
      "Epoch 00053: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3533 - dice_coef: 0.6468 - accuracy: 0.9973 - val_loss: 0.6345 - val_dice_coef: 0.3669 - val_accuracy: 0.9884\n",
      "Epoch 54/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3533 - dice_coef: 0.6465 - accuracy: 0.9973\n",
      "Epoch 00054: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3533 - dice_coef: 0.6465 - accuracy: 0.9973 - val_loss: 0.7971 - val_dice_coef: 0.2050 - val_accuracy: 0.9866\n",
      "Epoch 55/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3507 - dice_coef: 0.6493 - accuracy: 0.9974\n",
      "Epoch 00055: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3507 - dice_coef: 0.6493 - accuracy: 0.9974 - val_loss: 0.5910 - val_dice_coef: 0.4102 - val_accuracy: 0.9892\n",
      "Epoch 56/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3508 - dice_coef: 0.6492 - accuracy: 0.9974\n",
      "Epoch 00056: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3508 - dice_coef: 0.6492 - accuracy: 0.9974 - val_loss: 0.7098 - val_dice_coef: 0.2881 - val_accuracy: 0.9875\n",
      "Epoch 57/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3506 - dice_coef: 0.6495 - accuracy: 0.9974\n",
      "Epoch 00057: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3506 - dice_coef: 0.6495 - accuracy: 0.9974 - val_loss: 0.6343 - val_dice_coef: 0.3662 - val_accuracy: 0.9884\n",
      "Epoch 58/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3495 - dice_coef: 0.6502 - accuracy: 0.9974\n",
      "Epoch 00058: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3495 - dice_coef: 0.6502 - accuracy: 0.9974 - val_loss: 0.6630 - val_dice_coef: 0.3420 - val_accuracy: 0.9881\n",
      "Epoch 59/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3487 - dice_coef: 0.6511 - accuracy: 0.9974\n",
      "Epoch 00059: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3487 - dice_coef: 0.6511 - accuracy: 0.9974 - val_loss: 0.5821 - val_dice_coef: 0.4180 - val_accuracy: 0.9894\n",
      "Epoch 60/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3480 - dice_coef: 0.6520 - accuracy: 0.9974\n",
      "Epoch 00060: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 139s 463ms/step - loss: 0.3480 - dice_coef: 0.6520 - accuracy: 0.9974 - val_loss: 0.6091 - val_dice_coef: 0.3932 - val_accuracy: 0.9879\n",
      "Epoch 61/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3483 - dice_coef: 0.6517 - accuracy: 0.9974\n",
      "Epoch 00061: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3483 - dice_coef: 0.6517 - accuracy: 0.9974 - val_loss: 0.7149 - val_dice_coef: 0.2804 - val_accuracy: 0.9875\n",
      "Epoch 62/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3461 - dice_coef: 0.6539 - accuracy: 0.9974\n",
      "Epoch 00062: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3461 - dice_coef: 0.6539 - accuracy: 0.9974 - val_loss: 0.6417 - val_dice_coef: 0.3590 - val_accuracy: 0.9883\n",
      "Epoch 63/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3470 - dice_coef: 0.6531 - accuracy: 0.9974\n",
      "Epoch 00063: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.3470 - dice_coef: 0.6531 - accuracy: 0.9974 - val_loss: 0.5601 - val_dice_coef: 0.4385 - val_accuracy: 0.9892\n",
      "Epoch 64/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3452 - dice_coef: 0.6549 - accuracy: 0.9974\n",
      "Epoch 00064: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3452 - dice_coef: 0.6549 - accuracy: 0.9974 - val_loss: 0.5795 - val_dice_coef: 0.4200 - val_accuracy: 0.9896\n",
      "Epoch 65/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3458 - dice_coef: 0.6543 - accuracy: 0.9973\n",
      "Epoch 00065: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3458 - dice_coef: 0.6543 - accuracy: 0.9973 - val_loss: 0.8275 - val_dice_coef: 0.1703 - val_accuracy: 0.9861\n",
      "Epoch 66/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3449 - dice_coef: 0.6551 - accuracy: 0.9974\n",
      "Epoch 00066: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3449 - dice_coef: 0.6551 - accuracy: 0.9974 - val_loss: 0.6271 - val_dice_coef: 0.3722 - val_accuracy: 0.9886\n",
      "Epoch 67/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3439 - dice_coef: 0.6562 - accuracy: 0.9974\n",
      "Epoch 00067: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3439 - dice_coef: 0.6562 - accuracy: 0.9974 - val_loss: 0.5732 - val_dice_coef: 0.4260 - val_accuracy: 0.9892\n",
      "Epoch 68/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3417 - dice_coef: 0.6584 - accuracy: 0.9975\n",
      "Epoch 00068: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3417 - dice_coef: 0.6584 - accuracy: 0.9975 - val_loss: 0.6804 - val_dice_coef: 0.3225 - val_accuracy: 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3420 - dice_coef: 0.6581 - accuracy: 0.9975\n",
      "Epoch 00069: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3420 - dice_coef: 0.6581 - accuracy: 0.9975 - val_loss: 0.7560 - val_dice_coef: 0.2434 - val_accuracy: 0.9870\n",
      "Epoch 70/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3409 - dice_coef: 0.6589 - accuracy: 0.9975\n",
      "Epoch 00070: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3409 - dice_coef: 0.6589 - accuracy: 0.9975 - val_loss: 0.6843 - val_dice_coef: 0.3115 - val_accuracy: 0.9879\n",
      "Epoch 71/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3416 - dice_coef: 0.6581 - accuracy: 0.9974\n",
      "Epoch 00071: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3416 - dice_coef: 0.6581 - accuracy: 0.9974 - val_loss: 0.6531 - val_dice_coef: 0.3455 - val_accuracy: 0.9881\n",
      "Epoch 72/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3398 - dice_coef: 0.6601 - accuracy: 0.9975\n",
      "Epoch 00072: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3398 - dice_coef: 0.6601 - accuracy: 0.9975 - val_loss: 0.5608 - val_dice_coef: 0.4399 - val_accuracy: 0.9897\n",
      "Epoch 73/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3390 - dice_coef: 0.6605 - accuracy: 0.9975\n",
      "Epoch 00073: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3390 - dice_coef: 0.6605 - accuracy: 0.9975 - val_loss: 0.7397 - val_dice_coef: 0.2617 - val_accuracy: 0.9871\n",
      "Epoch 74/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3382 - dice_coef: 0.6618 - accuracy: 0.9975\n",
      "Epoch 00074: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3382 - dice_coef: 0.6618 - accuracy: 0.9975 - val_loss: 0.7037 - val_dice_coef: 0.2961 - val_accuracy: 0.9877\n",
      "Epoch 75/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3366 - dice_coef: 0.6634 - accuracy: 0.9975\n",
      "Epoch 00075: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3366 - dice_coef: 0.6634 - accuracy: 0.9975 - val_loss: 0.5629 - val_dice_coef: 0.4377 - val_accuracy: 0.9895\n",
      "Epoch 76/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3372 - dice_coef: 0.6628 - accuracy: 0.9975\n",
      "Epoch 00076: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3372 - dice_coef: 0.6628 - accuracy: 0.9975 - val_loss: 0.5794 - val_dice_coef: 0.4201 - val_accuracy: 0.9897\n",
      "Epoch 77/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3356 - dice_coef: 0.6645 - accuracy: 0.9975\n",
      "Epoch 00077: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3356 - dice_coef: 0.6645 - accuracy: 0.9975 - val_loss: 0.6007 - val_dice_coef: 0.3976 - val_accuracy: 0.9887\n",
      "Epoch 78/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3359 - dice_coef: 0.6641 - accuracy: 0.9975\n",
      "Epoch 00078: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3359 - dice_coef: 0.6641 - accuracy: 0.9975 - val_loss: 0.5669 - val_dice_coef: 0.4352 - val_accuracy: 0.9897\n",
      "Epoch 79/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3339 - dice_coef: 0.6661 - accuracy: 0.9975\n",
      "Epoch 00079: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3339 - dice_coef: 0.6661 - accuracy: 0.9975 - val_loss: 0.6105 - val_dice_coef: 0.3856 - val_accuracy: 0.9890\n",
      "Epoch 80/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3340 - dice_coef: 0.6661 - accuracy: 0.9975\n",
      "Epoch 00080: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3340 - dice_coef: 0.6661 - accuracy: 0.9975 - val_loss: 0.5759 - val_dice_coef: 0.4212 - val_accuracy: 0.9897\n",
      "Epoch 81/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3343 - dice_coef: 0.6653 - accuracy: 0.9975\n",
      "Epoch 00081: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3343 - dice_coef: 0.6653 - accuracy: 0.9975 - val_loss: 0.5649 - val_dice_coef: 0.4357 - val_accuracy: 0.9896\n",
      "Epoch 82/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3326 - dice_coef: 0.6673 - accuracy: 0.9975\n",
      "Epoch 00082: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3326 - dice_coef: 0.6673 - accuracy: 0.9975 - val_loss: 0.6579 - val_dice_coef: 0.3422 - val_accuracy: 0.9865\n",
      "Epoch 83/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3306 - dice_coef: 0.6693 - accuracy: 0.9976\n",
      "Epoch 00083: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3306 - dice_coef: 0.6693 - accuracy: 0.9976 - val_loss: 0.5876 - val_dice_coef: 0.4110 - val_accuracy: 0.9890\n",
      "Epoch 84/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3290 - dice_coef: 0.6710 - accuracy: 0.9976\n",
      "Epoch 00084: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3290 - dice_coef: 0.6710 - accuracy: 0.9976 - val_loss: 0.7819 - val_dice_coef: 0.2171 - val_accuracy: 0.9871\n",
      "Epoch 85/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3268 - dice_coef: 0.6732 - accuracy: 0.9977\n",
      "Epoch 00085: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3268 - dice_coef: 0.6732 - accuracy: 0.9977 - val_loss: 0.7449 - val_dice_coef: 0.2525 - val_accuracy: 0.9871\n",
      "Epoch 86/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3246 - dice_coef: 0.6754 - accuracy: 0.9977\n",
      "Epoch 00086: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3246 - dice_coef: 0.6754 - accuracy: 0.9977 - val_loss: 0.8221 - val_dice_coef: 0.1730 - val_accuracy: 0.9866\n",
      "Epoch 87/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3236 - dice_coef: 0.6764 - accuracy: 0.9978\n",
      "Epoch 00087: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3236 - dice_coef: 0.6764 - accuracy: 0.9978 - val_loss: 0.6295 - val_dice_coef: 0.3671 - val_accuracy: 0.9878\n",
      "Epoch 88/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3222 - dice_coef: 0.6778 - accuracy: 0.9978\n",
      "Epoch 00088: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3222 - dice_coef: 0.6778 - accuracy: 0.9978 - val_loss: 0.6960 - val_dice_coef: 0.3080 - val_accuracy: 0.9875\n",
      "Epoch 89/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3220 - dice_coef: 0.6780 - accuracy: 0.9978\n",
      "Epoch 00089: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3220 - dice_coef: 0.6780 - accuracy: 0.9978 - val_loss: 0.5850 - val_dice_coef: 0.4135 - val_accuracy: 0.9889\n",
      "Epoch 90/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3215 - dice_coef: 0.6784 - accuracy: 0.9978\n",
      "Epoch 00090: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3215 - dice_coef: 0.6784 - accuracy: 0.9978 - val_loss: 0.6210 - val_dice_coef: 0.3760 - val_accuracy: 0.9885\n",
      "Epoch 91/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3200 - dice_coef: 0.6800 - accuracy: 0.9978\n",
      "Epoch 00091: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3200 - dice_coef: 0.6800 - accuracy: 0.9978 - val_loss: 0.6222 - val_dice_coef: 0.3750 - val_accuracy: 0.9888\n",
      "Epoch 92/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3193 - dice_coef: 0.6807 - accuracy: 0.9978\n",
      "Epoch 00092: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3193 - dice_coef: 0.6807 - accuracy: 0.9978 - val_loss: 0.7556 - val_dice_coef: 0.2463 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3193 - dice_coef: 0.6807 - accuracy: 0.9978\n",
      "Epoch 00093: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3193 - dice_coef: 0.6807 - accuracy: 0.9978 - val_loss: 0.6473 - val_dice_coef: 0.3486 - val_accuracy: 0.9882\n",
      "Epoch 94/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3187 - dice_coef: 0.6813 - accuracy: 0.9978\n",
      "Epoch 00094: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3187 - dice_coef: 0.6813 - accuracy: 0.9978 - val_loss: 0.8125 - val_dice_coef: 0.1891 - val_accuracy: 0.9865\n",
      "Epoch 95/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3176 - dice_coef: 0.6825 - accuracy: 0.9978\n",
      "Epoch 00095: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.3176 - dice_coef: 0.6825 - accuracy: 0.9978 - val_loss: 0.7781 - val_dice_coef: 0.2239 - val_accuracy: 0.9867\n",
      "Epoch 96/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3173 - dice_coef: 0.6827 - accuracy: 0.9978\n",
      "Epoch 00096: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3173 - dice_coef: 0.6827 - accuracy: 0.9978 - val_loss: 0.6911 - val_dice_coef: 0.3083 - val_accuracy: 0.9881\n",
      "Epoch 97/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3161 - dice_coef: 0.6838 - accuracy: 0.9978\n",
      "Epoch 00097: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3161 - dice_coef: 0.6838 - accuracy: 0.9978 - val_loss: 0.7880 - val_dice_coef: 0.2140 - val_accuracy: 0.9870\n",
      "Epoch 98/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3163 - dice_coef: 0.6837 - accuracy: 0.9978\n",
      "Epoch 00098: val_loss did not improve from 0.55190\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3163 - dice_coef: 0.6837 - accuracy: 0.9978 - val_loss: 0.6431 - val_dice_coef: 0.3612 - val_accuracy: 0.9887\n",
      "Epoch 99/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3150 - dice_coef: 0.6850 - accuracy: 0.9978\n",
      "Epoch 00099: val_loss improved from 0.55190 to 0.54149, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 455ms/step - loss: 0.3150 - dice_coef: 0.6850 - accuracy: 0.9978 - val_loss: 0.5415 - val_dice_coef: 0.4596 - val_accuracy: 0.9901\n",
      "Epoch 100/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3144 - dice_coef: 0.6855 - accuracy: 0.9979\n",
      "Epoch 00100: val_loss did not improve from 0.54149\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3144 - dice_coef: 0.6855 - accuracy: 0.9979 - val_loss: 0.6476 - val_dice_coef: 0.3528 - val_accuracy: 0.9885\n",
      "Epoch 101/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3136 - dice_coef: 0.6864 - accuracy: 0.9979\n",
      "Epoch 00101: val_loss did not improve from 0.54149\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3136 - dice_coef: 0.6864 - accuracy: 0.9979 - val_loss: 0.5952 - val_dice_coef: 0.4065 - val_accuracy: 0.9894\n",
      "Epoch 102/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3130 - dice_coef: 0.6870 - accuracy: 0.9979\n",
      "Epoch 00102: val_loss did not improve from 0.54149\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3130 - dice_coef: 0.6870 - accuracy: 0.9979 - val_loss: 0.6169 - val_dice_coef: 0.3858 - val_accuracy: 0.9891\n",
      "Epoch 103/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3123 - dice_coef: 0.6877 - accuracy: 0.9979\n",
      "Epoch 00103: val_loss did not improve from 0.54149\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3123 - dice_coef: 0.6877 - accuracy: 0.9979 - val_loss: 0.7451 - val_dice_coef: 0.2607 - val_accuracy: 0.9875\n",
      "Epoch 104/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3116 - dice_coef: 0.6884 - accuracy: 0.9979\n",
      "Epoch 00104: val_loss improved from 0.54149 to 0.53702, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 455ms/step - loss: 0.3116 - dice_coef: 0.6884 - accuracy: 0.9979 - val_loss: 0.5370 - val_dice_coef: 0.4632 - val_accuracy: 0.9895\n",
      "Epoch 105/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3107 - dice_coef: 0.6893 - accuracy: 0.9979\n",
      "Epoch 00105: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3107 - dice_coef: 0.6893 - accuracy: 0.9979 - val_loss: 0.5913 - val_dice_coef: 0.4087 - val_accuracy: 0.9891\n",
      "Epoch 106/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3106 - dice_coef: 0.6894 - accuracy: 0.9979\n",
      "Epoch 00106: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3106 - dice_coef: 0.6894 - accuracy: 0.9979 - val_loss: 0.5662 - val_dice_coef: 0.4333 - val_accuracy: 0.9895\n",
      "Epoch 107/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3095 - dice_coef: 0.6904 - accuracy: 0.9979\n",
      "Epoch 00107: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.3095 - dice_coef: 0.6904 - accuracy: 0.9979 - val_loss: 0.5558 - val_dice_coef: 0.4446 - val_accuracy: 0.9895\n",
      "Epoch 108/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3091 - dice_coef: 0.6909 - accuracy: 0.9979\n",
      "Epoch 00108: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3091 - dice_coef: 0.6909 - accuracy: 0.9979 - val_loss: 0.6033 - val_dice_coef: 0.3978 - val_accuracy: 0.9893\n",
      "Epoch 109/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3084 - dice_coef: 0.6915 - accuracy: 0.9979\n",
      "Epoch 00109: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3084 - dice_coef: 0.6915 - accuracy: 0.9979 - val_loss: 0.5906 - val_dice_coef: 0.4084 - val_accuracy: 0.9893\n",
      "Epoch 110/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3079 - dice_coef: 0.6920 - accuracy: 0.9979\n",
      "Epoch 00110: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3079 - dice_coef: 0.6920 - accuracy: 0.9979 - val_loss: 0.5553 - val_dice_coef: 0.4462 - val_accuracy: 0.9892\n",
      "Epoch 111/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3074 - dice_coef: 0.6926 - accuracy: 0.9979\n",
      "Epoch 00111: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3074 - dice_coef: 0.6926 - accuracy: 0.9979 - val_loss: 0.5939 - val_dice_coef: 0.4038 - val_accuracy: 0.9891\n",
      "Epoch 112/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3062 - dice_coef: 0.6939 - accuracy: 0.9979\n",
      "Epoch 00112: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3062 - dice_coef: 0.6939 - accuracy: 0.9979 - val_loss: 0.5517 - val_dice_coef: 0.4514 - val_accuracy: 0.9896\n",
      "Epoch 113/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3057 - dice_coef: 0.6944 - accuracy: 0.9979\n",
      "Epoch 00113: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3057 - dice_coef: 0.6944 - accuracy: 0.9979 - val_loss: 0.5470 - val_dice_coef: 0.4557 - val_accuracy: 0.9897\n",
      "Epoch 114/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3053 - dice_coef: 0.6946 - accuracy: 0.9979\n",
      "Epoch 00114: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3053 - dice_coef: 0.6946 - accuracy: 0.9979 - val_loss: 0.5541 - val_dice_coef: 0.4406 - val_accuracy: 0.9894\n",
      "Epoch 115/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3042 - dice_coef: 0.6957 - accuracy: 0.9980\n",
      "Epoch 00115: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3042 - dice_coef: 0.6957 - accuracy: 0.9980 - val_loss: 0.5912 - val_dice_coef: 0.4110 - val_accuracy: 0.9894\n",
      "Epoch 116/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 0.3036 - dice_coef: 0.6964 - accuracy: 0.9979\n",
      "Epoch 00116: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3036 - dice_coef: 0.6964 - accuracy: 0.9979 - val_loss: 0.5802 - val_dice_coef: 0.4219 - val_accuracy: 0.9894\n",
      "Epoch 117/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3031 - dice_coef: 0.6969 - accuracy: 0.9979\n",
      "Epoch 00117: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3031 - dice_coef: 0.6969 - accuracy: 0.9979 - val_loss: 0.6288 - val_dice_coef: 0.3741 - val_accuracy: 0.9887\n",
      "Epoch 118/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3028 - dice_coef: 0.6972 - accuracy: 0.9980\n",
      "Epoch 00118: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.3028 - dice_coef: 0.6972 - accuracy: 0.9980 - val_loss: 0.6082 - val_dice_coef: 0.3918 - val_accuracy: 0.9885\n",
      "Epoch 119/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3021 - dice_coef: 0.6979 - accuracy: 0.9980\n",
      "Epoch 00119: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3021 - dice_coef: 0.6979 - accuracy: 0.9980 - val_loss: 0.5515 - val_dice_coef: 0.4508 - val_accuracy: 0.9899\n",
      "Epoch 120/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3012 - dice_coef: 0.6988 - accuracy: 0.9980\n",
      "Epoch 00120: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3012 - dice_coef: 0.6988 - accuracy: 0.9980 - val_loss: 0.5418 - val_dice_coef: 0.4611 - val_accuracy: 0.9894\n",
      "Epoch 121/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3010 - dice_coef: 0.6989 - accuracy: 0.9980\n",
      "Epoch 00121: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.3010 - dice_coef: 0.6989 - accuracy: 0.9980 - val_loss: 0.6720 - val_dice_coef: 0.3296 - val_accuracy: 0.9875\n",
      "Epoch 122/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2998 - dice_coef: 0.7002 - accuracy: 0.9980\n",
      "Epoch 00122: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2998 - dice_coef: 0.7002 - accuracy: 0.9980 - val_loss: 0.6681 - val_dice_coef: 0.3319 - val_accuracy: 0.9877\n",
      "Epoch 123/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2995 - dice_coef: 0.7005 - accuracy: 0.9980\n",
      "Epoch 00123: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2995 - dice_coef: 0.7005 - accuracy: 0.9980 - val_loss: 0.6755 - val_dice_coef: 0.3233 - val_accuracy: 0.9878\n",
      "Epoch 124/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2986 - dice_coef: 0.7014 - accuracy: 0.9980\n",
      "Epoch 00124: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2986 - dice_coef: 0.7014 - accuracy: 0.9980 - val_loss: 0.5932 - val_dice_coef: 0.4044 - val_accuracy: 0.9866\n",
      "Epoch 125/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2979 - dice_coef: 0.7021 - accuracy: 0.9980\n",
      "Epoch 00125: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2979 - dice_coef: 0.7021 - accuracy: 0.9980 - val_loss: 0.6707 - val_dice_coef: 0.3303 - val_accuracy: 0.9878\n",
      "Epoch 126/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2972 - dice_coef: 0.7028 - accuracy: 0.9980\n",
      "Epoch 00126: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2972 - dice_coef: 0.7028 - accuracy: 0.9980 - val_loss: 0.6826 - val_dice_coef: 0.3149 - val_accuracy: 0.9874\n",
      "Epoch 127/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2974 - dice_coef: 0.7026 - accuracy: 0.9980\n",
      "Epoch 00127: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2974 - dice_coef: 0.7026 - accuracy: 0.9980 - val_loss: 0.6630 - val_dice_coef: 0.3414 - val_accuracy: 0.9871\n",
      "Epoch 128/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2959 - dice_coef: 0.7041 - accuracy: 0.9980\n",
      "Epoch 00128: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2959 - dice_coef: 0.7041 - accuracy: 0.9980 - val_loss: 0.6560 - val_dice_coef: 0.3448 - val_accuracy: 0.9877\n",
      "Epoch 129/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2957 - dice_coef: 0.7043 - accuracy: 0.9980\n",
      "Epoch 00129: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2957 - dice_coef: 0.7043 - accuracy: 0.9980 - val_loss: 0.6375 - val_dice_coef: 0.3542 - val_accuracy: 0.9882\n",
      "Epoch 130/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2950 - dice_coef: 0.7050 - accuracy: 0.9980\n",
      "Epoch 00130: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2950 - dice_coef: 0.7050 - accuracy: 0.9980 - val_loss: 0.6244 - val_dice_coef: 0.3720 - val_accuracy: 0.9885\n",
      "Epoch 131/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2941 - dice_coef: 0.7059 - accuracy: 0.9980\n",
      "Epoch 00131: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2941 - dice_coef: 0.7059 - accuracy: 0.9980 - val_loss: 0.6637 - val_dice_coef: 0.3370 - val_accuracy: 0.9879\n",
      "Epoch 132/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2935 - dice_coef: 0.7064 - accuracy: 0.9980\n",
      "Epoch 00132: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2935 - dice_coef: 0.7064 - accuracy: 0.9980 - val_loss: 0.5844 - val_dice_coef: 0.4154 - val_accuracy: 0.9884\n",
      "Epoch 133/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2930 - dice_coef: 0.7070 - accuracy: 0.9980\n",
      "Epoch 00133: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2930 - dice_coef: 0.7070 - accuracy: 0.9980 - val_loss: 0.7317 - val_dice_coef: 0.2751 - val_accuracy: 0.9866\n",
      "Epoch 134/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2923 - dice_coef: 0.7076 - accuracy: 0.9980\n",
      "Epoch 00134: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2923 - dice_coef: 0.7076 - accuracy: 0.9980 - val_loss: 0.7068 - val_dice_coef: 0.2934 - val_accuracy: 0.9872\n",
      "Epoch 135/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2923 - dice_coef: 0.7077 - accuracy: 0.9980\n",
      "Epoch 00135: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2923 - dice_coef: 0.7077 - accuracy: 0.9980 - val_loss: 0.6860 - val_dice_coef: 0.3175 - val_accuracy: 0.9878\n",
      "Epoch 136/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2913 - dice_coef: 0.7087 - accuracy: 0.9980\n",
      "Epoch 00136: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2913 - dice_coef: 0.7087 - accuracy: 0.9980 - val_loss: 0.6252 - val_dice_coef: 0.3754 - val_accuracy: 0.9879\n",
      "Epoch 137/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2906 - dice_coef: 0.7093 - accuracy: 0.9980\n",
      "Epoch 00137: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2906 - dice_coef: 0.7093 - accuracy: 0.9980 - val_loss: 0.7187 - val_dice_coef: 0.2765 - val_accuracy: 0.9874\n",
      "Epoch 138/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2895 - dice_coef: 0.7105 - accuracy: 0.9981\n",
      "Epoch 00138: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2895 - dice_coef: 0.7105 - accuracy: 0.9981 - val_loss: 0.6977 - val_dice_coef: 0.3047 - val_accuracy: 0.9876\n",
      "Epoch 139/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2899 - dice_coef: 0.7102 - accuracy: 0.9981\n",
      "Epoch 00139: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2899 - dice_coef: 0.7102 - accuracy: 0.9981 - val_loss: 0.6204 - val_dice_coef: 0.3799 - val_accuracy: 0.9887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2886 - dice_coef: 0.7114 - accuracy: 0.9981\n",
      "Epoch 00140: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2886 - dice_coef: 0.7114 - accuracy: 0.9981 - val_loss: 0.6809 - val_dice_coef: 0.3184 - val_accuracy: 0.9876\n",
      "Epoch 141/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2877 - dice_coef: 0.7123 - accuracy: 0.9981\n",
      "Epoch 00141: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2877 - dice_coef: 0.7123 - accuracy: 0.9981 - val_loss: 0.7246 - val_dice_coef: 0.2816 - val_accuracy: 0.9873\n",
      "Epoch 142/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2874 - dice_coef: 0.7126 - accuracy: 0.9981\n",
      "Epoch 00142: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2874 - dice_coef: 0.7126 - accuracy: 0.9981 - val_loss: 0.6042 - val_dice_coef: 0.3953 - val_accuracy: 0.9887\n",
      "Epoch 143/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2867 - dice_coef: 0.7133 - accuracy: 0.9981\n",
      "Epoch 00143: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2867 - dice_coef: 0.7133 - accuracy: 0.9981 - val_loss: 0.6213 - val_dice_coef: 0.3793 - val_accuracy: 0.9887\n",
      "Epoch 144/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2863 - dice_coef: 0.7137 - accuracy: 0.9981\n",
      "Epoch 00144: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2863 - dice_coef: 0.7137 - accuracy: 0.9981 - val_loss: 0.6634 - val_dice_coef: 0.3333 - val_accuracy: 0.9880\n",
      "Epoch 145/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2859 - dice_coef: 0.7141 - accuracy: 0.9981\n",
      "Epoch 00145: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2859 - dice_coef: 0.7141 - accuracy: 0.9981 - val_loss: 0.6843 - val_dice_coef: 0.3216 - val_accuracy: 0.9877\n",
      "Epoch 146/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2848 - dice_coef: 0.7152 - accuracy: 0.9981\n",
      "Epoch 00146: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2848 - dice_coef: 0.7152 - accuracy: 0.9981 - val_loss: 0.5607 - val_dice_coef: 0.4415 - val_accuracy: 0.9892\n",
      "Epoch 147/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2843 - dice_coef: 0.7157 - accuracy: 0.9981\n",
      "Epoch 00147: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2843 - dice_coef: 0.7157 - accuracy: 0.9981 - val_loss: 0.5786 - val_dice_coef: 0.4216 - val_accuracy: 0.9880\n",
      "Epoch 148/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2834 - dice_coef: 0.7165 - accuracy: 0.9981\n",
      "Epoch 00148: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2834 - dice_coef: 0.7165 - accuracy: 0.9981 - val_loss: 0.5850 - val_dice_coef: 0.4116 - val_accuracy: 0.9881\n",
      "Epoch 149/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2827 - dice_coef: 0.7173 - accuracy: 0.9981\n",
      "Epoch 00149: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2827 - dice_coef: 0.7173 - accuracy: 0.9981 - val_loss: 0.5912 - val_dice_coef: 0.4034 - val_accuracy: 0.9884\n",
      "Epoch 150/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2823 - dice_coef: 0.7178 - accuracy: 0.9981\n",
      "Epoch 00150: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2823 - dice_coef: 0.7178 - accuracy: 0.9981 - val_loss: 0.5861 - val_dice_coef: 0.4142 - val_accuracy: 0.9884\n",
      "Epoch 151/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2819 - dice_coef: 0.7182 - accuracy: 0.9981\n",
      "Epoch 00151: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2819 - dice_coef: 0.7182 - accuracy: 0.9981 - val_loss: 0.5933 - val_dice_coef: 0.4070 - val_accuracy: 0.9891\n",
      "Epoch 152/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2815 - dice_coef: 0.7186 - accuracy: 0.9981\n",
      "Epoch 00152: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2815 - dice_coef: 0.7186 - accuracy: 0.9981 - val_loss: 0.6401 - val_dice_coef: 0.3618 - val_accuracy: 0.9880\n",
      "Epoch 153/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2807 - dice_coef: 0.7193 - accuracy: 0.9982\n",
      "Epoch 00153: val_loss did not improve from 0.53702\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2807 - dice_coef: 0.7193 - accuracy: 0.9982 - val_loss: 0.6411 - val_dice_coef: 0.3581 - val_accuracy: 0.9881\n",
      "Epoch 154/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2798 - dice_coef: 0.7202 - accuracy: 0.9982\n",
      "Epoch 00154: val_loss improved from 0.53702 to 0.52507, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 137s 455ms/step - loss: 0.2798 - dice_coef: 0.7202 - accuracy: 0.9982 - val_loss: 0.5251 - val_dice_coef: 0.4714 - val_accuracy: 0.9896\n",
      "Epoch 155/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2792 - dice_coef: 0.7208 - accuracy: 0.9982\n",
      "Epoch 00155: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2792 - dice_coef: 0.7208 - accuracy: 0.9982 - val_loss: 0.5983 - val_dice_coef: 0.3947 - val_accuracy: 0.9891\n",
      "Epoch 156/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2785 - dice_coef: 0.7214 - accuracy: 0.9982\n",
      "Epoch 00156: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2785 - dice_coef: 0.7214 - accuracy: 0.9982 - val_loss: 0.5351 - val_dice_coef: 0.4655 - val_accuracy: 0.9891\n",
      "Epoch 157/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2780 - dice_coef: 0.7220 - accuracy: 0.9982\n",
      "Epoch 00157: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2780 - dice_coef: 0.7220 - accuracy: 0.9982 - val_loss: 0.6453 - val_dice_coef: 0.3551 - val_accuracy: 0.9881\n",
      "Epoch 158/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2780 - dice_coef: 0.7220 - accuracy: 0.9981\n",
      "Epoch 00158: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2780 - dice_coef: 0.7220 - accuracy: 0.9981 - val_loss: 0.5296 - val_dice_coef: 0.4724 - val_accuracy: 0.9892\n",
      "Epoch 159/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2765 - dice_coef: 0.7236 - accuracy: 0.9982\n",
      "Epoch 00159: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2765 - dice_coef: 0.7236 - accuracy: 0.9982 - val_loss: 0.5450 - val_dice_coef: 0.4584 - val_accuracy: 0.9894\n",
      "Epoch 160/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2760 - dice_coef: 0.7239 - accuracy: 0.9982\n",
      "Epoch 00160: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2760 - dice_coef: 0.7239 - accuracy: 0.9982 - val_loss: 0.6008 - val_dice_coef: 0.4024 - val_accuracy: 0.9887\n",
      "Epoch 161/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2753 - dice_coef: 0.7246 - accuracy: 0.9982\n",
      "Epoch 00161: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2753 - dice_coef: 0.7246 - accuracy: 0.9982 - val_loss: 0.5330 - val_dice_coef: 0.4665 - val_accuracy: 0.9892\n",
      "Epoch 162/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2748 - dice_coef: 0.7251 - accuracy: 0.9982\n",
      "Epoch 00162: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2748 - dice_coef: 0.7251 - accuracy: 0.9982 - val_loss: 0.6746 - val_dice_coef: 0.3276 - val_accuracy: 0.9879\n",
      "Epoch 163/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2744 - dice_coef: 0.7255 - accuracy: 0.9982\n",
      "Epoch 00163: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2744 - dice_coef: 0.7255 - accuracy: 0.9982 - val_loss: 0.5747 - val_dice_coef: 0.4244 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2736 - dice_coef: 0.7264 - accuracy: 0.9982\n",
      "Epoch 00164: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2736 - dice_coef: 0.7264 - accuracy: 0.9982 - val_loss: 0.5797 - val_dice_coef: 0.4183 - val_accuracy: 0.9891\n",
      "Epoch 165/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2732 - dice_coef: 0.7268 - accuracy: 0.9982\n",
      "Epoch 00165: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2732 - dice_coef: 0.7268 - accuracy: 0.9982 - val_loss: 0.5493 - val_dice_coef: 0.4478 - val_accuracy: 0.9896\n",
      "Epoch 166/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2725 - dice_coef: 0.7275 - accuracy: 0.9982\n",
      "Epoch 00166: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2725 - dice_coef: 0.7275 - accuracy: 0.9982 - val_loss: 0.5252 - val_dice_coef: 0.4781 - val_accuracy: 0.9897\n",
      "Epoch 167/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2720 - dice_coef: 0.7280 - accuracy: 0.9982\n",
      "Epoch 00167: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2720 - dice_coef: 0.7280 - accuracy: 0.9982 - val_loss: 0.6120 - val_dice_coef: 0.3899 - val_accuracy: 0.9885\n",
      "Epoch 168/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2711 - dice_coef: 0.7289 - accuracy: 0.9982\n",
      "Epoch 00168: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2711 - dice_coef: 0.7289 - accuracy: 0.9982 - val_loss: 0.5313 - val_dice_coef: 0.4653 - val_accuracy: 0.9895\n",
      "Epoch 169/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2704 - dice_coef: 0.7296 - accuracy: 0.9982\n",
      "Epoch 00169: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2704 - dice_coef: 0.7296 - accuracy: 0.9982 - val_loss: 0.5435 - val_dice_coef: 0.4558 - val_accuracy: 0.9897\n",
      "Epoch 170/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2700 - dice_coef: 0.7300 - accuracy: 0.9982\n",
      "Epoch 00170: val_loss did not improve from 0.52507\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2700 - dice_coef: 0.7300 - accuracy: 0.9982 - val_loss: 0.6108 - val_dice_coef: 0.3891 - val_accuracy: 0.9882\n",
      "Epoch 171/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2695 - dice_coef: 0.7305 - accuracy: 0.9982\n",
      "Epoch 00171: val_loss improved from 0.52507 to 0.52311, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.2695 - dice_coef: 0.7305 - accuracy: 0.9982 - val_loss: 0.5231 - val_dice_coef: 0.4716 - val_accuracy: 0.9898\n",
      "Epoch 172/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2692 - dice_coef: 0.7308 - accuracy: 0.9982\n",
      "Epoch 00172: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2692 - dice_coef: 0.7308 - accuracy: 0.9982 - val_loss: 0.5334 - val_dice_coef: 0.4696 - val_accuracy: 0.9879\n",
      "Epoch 173/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2681 - dice_coef: 0.7319 - accuracy: 0.9983\n",
      "Epoch 00173: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2681 - dice_coef: 0.7319 - accuracy: 0.9983 - val_loss: 0.5910 - val_dice_coef: 0.4092 - val_accuracy: 0.9883\n",
      "Epoch 174/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2682 - dice_coef: 0.7317 - accuracy: 0.9982\n",
      "Epoch 00174: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2682 - dice_coef: 0.7317 - accuracy: 0.9982 - val_loss: 0.5251 - val_dice_coef: 0.4755 - val_accuracy: 0.9898\n",
      "Epoch 175/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2670 - dice_coef: 0.7330 - accuracy: 0.9983\n",
      "Epoch 00175: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2670 - dice_coef: 0.7330 - accuracy: 0.9983 - val_loss: 0.5666 - val_dice_coef: 0.4364 - val_accuracy: 0.9892\n",
      "Epoch 176/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2662 - dice_coef: 0.7337 - accuracy: 0.9983\n",
      "Epoch 00176: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2662 - dice_coef: 0.7337 - accuracy: 0.9983 - val_loss: 0.5668 - val_dice_coef: 0.4349 - val_accuracy: 0.9889\n",
      "Epoch 177/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2660 - dice_coef: 0.7341 - accuracy: 0.9983\n",
      "Epoch 00177: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2660 - dice_coef: 0.7341 - accuracy: 0.9983 - val_loss: 0.5244 - val_dice_coef: 0.4739 - val_accuracy: 0.9893\n",
      "Epoch 178/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2654 - dice_coef: 0.7347 - accuracy: 0.9983\n",
      "Epoch 00178: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2654 - dice_coef: 0.7347 - accuracy: 0.9983 - val_loss: 0.5394 - val_dice_coef: 0.4646 - val_accuracy: 0.9894\n",
      "Epoch 179/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2648 - dice_coef: 0.7352 - accuracy: 0.9983\n",
      "Epoch 00179: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2648 - dice_coef: 0.7352 - accuracy: 0.9983 - val_loss: 0.6599 - val_dice_coef: 0.3425 - val_accuracy: 0.9881\n",
      "Epoch 180/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2637 - dice_coef: 0.7363 - accuracy: 0.9983\n",
      "Epoch 00180: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2637 - dice_coef: 0.7363 - accuracy: 0.9983 - val_loss: 0.5794 - val_dice_coef: 0.4199 - val_accuracy: 0.9891\n",
      "Epoch 181/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2635 - dice_coef: 0.7365 - accuracy: 0.9983\n",
      "Epoch 00181: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2635 - dice_coef: 0.7365 - accuracy: 0.9983 - val_loss: 0.5396 - val_dice_coef: 0.4531 - val_accuracy: 0.9888\n",
      "Epoch 182/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2633 - dice_coef: 0.7367 - accuracy: 0.9983\n",
      "Epoch 00182: val_loss did not improve from 0.52311\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2633 - dice_coef: 0.7367 - accuracy: 0.9983 - val_loss: 0.5292 - val_dice_coef: 0.4741 - val_accuracy: 0.9893\n",
      "Epoch 183/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2623 - dice_coef: 0.7377 - accuracy: 0.9983\n",
      "Epoch 00183: val_loss improved from 0.52311 to 0.51848, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.2623 - dice_coef: 0.7377 - accuracy: 0.9983 - val_loss: 0.5185 - val_dice_coef: 0.4823 - val_accuracy: 0.9885\n",
      "Epoch 184/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2615 - dice_coef: 0.7385 - accuracy: 0.9983\n",
      "Epoch 00184: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2615 - dice_coef: 0.7385 - accuracy: 0.9983 - val_loss: 0.6049 - val_dice_coef: 0.3961 - val_accuracy: 0.9876\n",
      "Epoch 185/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2611 - dice_coef: 0.7388 - accuracy: 0.9983\n",
      "Epoch 00185: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2611 - dice_coef: 0.7388 - accuracy: 0.9983 - val_loss: 0.5416 - val_dice_coef: 0.4587 - val_accuracy: 0.9892\n",
      "Epoch 186/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2607 - dice_coef: 0.7392 - accuracy: 0.9983\n",
      "Epoch 00186: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2607 - dice_coef: 0.7392 - accuracy: 0.9983 - val_loss: 0.5272 - val_dice_coef: 0.4735 - val_accuracy: 0.9888\n",
      "Epoch 187/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 0.2598 - dice_coef: 0.7403 - accuracy: 0.9983\n",
      "Epoch 00187: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2598 - dice_coef: 0.7403 - accuracy: 0.9983 - val_loss: 0.5279 - val_dice_coef: 0.4706 - val_accuracy: 0.9888\n",
      "Epoch 188/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2594 - dice_coef: 0.7406 - accuracy: 0.9983\n",
      "Epoch 00188: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2594 - dice_coef: 0.7406 - accuracy: 0.9983 - val_loss: 0.5665 - val_dice_coef: 0.4361 - val_accuracy: 0.9887\n",
      "Epoch 189/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2586 - dice_coef: 0.7414 - accuracy: 0.9983\n",
      "Epoch 00189: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2586 - dice_coef: 0.7414 - accuracy: 0.9983 - val_loss: 0.5380 - val_dice_coef: 0.4642 - val_accuracy: 0.9889\n",
      "Epoch 190/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2579 - dice_coef: 0.7421 - accuracy: 0.9983\n",
      "Epoch 00190: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2579 - dice_coef: 0.7421 - accuracy: 0.9983 - val_loss: 0.5229 - val_dice_coef: 0.4731 - val_accuracy: 0.9891\n",
      "Epoch 191/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2575 - dice_coef: 0.7425 - accuracy: 0.9983\n",
      "Epoch 00191: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.2575 - dice_coef: 0.7425 - accuracy: 0.9983 - val_loss: 0.5578 - val_dice_coef: 0.4429 - val_accuracy: 0.9891\n",
      "Epoch 192/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2570 - dice_coef: 0.7430 - accuracy: 0.9983\n",
      "Epoch 00192: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2570 - dice_coef: 0.7430 - accuracy: 0.9983 - val_loss: 0.5494 - val_dice_coef: 0.4527 - val_accuracy: 0.9884\n",
      "Epoch 193/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2562 - dice_coef: 0.7438 - accuracy: 0.9984\n",
      "Epoch 00193: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2562 - dice_coef: 0.7438 - accuracy: 0.9984 - val_loss: 0.7181 - val_dice_coef: 0.2846 - val_accuracy: 0.9868\n",
      "Epoch 194/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2557 - dice_coef: 0.7443 - accuracy: 0.9984\n",
      "Epoch 00194: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2557 - dice_coef: 0.7443 - accuracy: 0.9984 - val_loss: 0.5264 - val_dice_coef: 0.4752 - val_accuracy: 0.9887\n",
      "Epoch 195/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2553 - dice_coef: 0.7447 - accuracy: 0.9984\n",
      "Epoch 00195: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2553 - dice_coef: 0.7447 - accuracy: 0.9984 - val_loss: 0.5415 - val_dice_coef: 0.4586 - val_accuracy: 0.9891\n",
      "Epoch 196/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2551 - dice_coef: 0.7449 - accuracy: 0.9984\n",
      "Epoch 00196: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2551 - dice_coef: 0.7449 - accuracy: 0.9984 - val_loss: 0.6193 - val_dice_coef: 0.3743 - val_accuracy: 0.9880\n",
      "Epoch 197/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2542 - dice_coef: 0.7459 - accuracy: 0.9984\n",
      "Epoch 00197: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2542 - dice_coef: 0.7459 - accuracy: 0.9984 - val_loss: 0.5662 - val_dice_coef: 0.4338 - val_accuracy: 0.9887\n",
      "Epoch 198/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2535 - dice_coef: 0.7465 - accuracy: 0.9984\n",
      "Epoch 00198: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2535 - dice_coef: 0.7465 - accuracy: 0.9984 - val_loss: 0.6110 - val_dice_coef: 0.3948 - val_accuracy: 0.9875\n",
      "Epoch 199/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2528 - dice_coef: 0.7472 - accuracy: 0.9984\n",
      "Epoch 00199: val_loss did not improve from 0.51848\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2528 - dice_coef: 0.7472 - accuracy: 0.9984 - val_loss: 0.5280 - val_dice_coef: 0.4737 - val_accuracy: 0.9886\n",
      "Epoch 200/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2526 - dice_coef: 0.7474 - accuracy: 0.9984\n",
      "Epoch 00200: val_loss improved from 0.51848 to 0.51133, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 455ms/step - loss: 0.2526 - dice_coef: 0.7474 - accuracy: 0.9984 - val_loss: 0.5113 - val_dice_coef: 0.4870 - val_accuracy: 0.9890\n",
      "Epoch 201/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2517 - dice_coef: 0.7483 - accuracy: 0.9984\n",
      "Epoch 00201: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2517 - dice_coef: 0.7483 - accuracy: 0.9984 - val_loss: 0.5168 - val_dice_coef: 0.4843 - val_accuracy: 0.9896\n",
      "Epoch 202/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2511 - dice_coef: 0.7489 - accuracy: 0.9984\n",
      "Epoch 00202: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2511 - dice_coef: 0.7489 - accuracy: 0.9984 - val_loss: 0.5457 - val_dice_coef: 0.4491 - val_accuracy: 0.9891\n",
      "Epoch 203/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2507 - dice_coef: 0.7493 - accuracy: 0.9984\n",
      "Epoch 00203: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2507 - dice_coef: 0.7493 - accuracy: 0.9984 - val_loss: 0.5597 - val_dice_coef: 0.4439 - val_accuracy: 0.9881\n",
      "Epoch 204/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2499 - dice_coef: 0.7499 - accuracy: 0.9984\n",
      "Epoch 00204: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2499 - dice_coef: 0.7499 - accuracy: 0.9984 - val_loss: 0.5391 - val_dice_coef: 0.4621 - val_accuracy: 0.9887\n",
      "Epoch 205/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2488 - dice_coef: 0.7512 - accuracy: 0.9984\n",
      "Epoch 00205: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2488 - dice_coef: 0.7512 - accuracy: 0.9984 - val_loss: 0.5238 - val_dice_coef: 0.4792 - val_accuracy: 0.9888\n",
      "Epoch 206/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2489 - dice_coef: 0.7511 - accuracy: 0.9984\n",
      "Epoch 00206: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2489 - dice_coef: 0.7511 - accuracy: 0.9984 - val_loss: 0.5463 - val_dice_coef: 0.4537 - val_accuracy: 0.9889\n",
      "Epoch 207/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2481 - dice_coef: 0.7519 - accuracy: 0.9984\n",
      "Epoch 00207: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2481 - dice_coef: 0.7519 - accuracy: 0.9984 - val_loss: 0.5492 - val_dice_coef: 0.4475 - val_accuracy: 0.9887\n",
      "Epoch 208/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2479 - dice_coef: 0.7521 - accuracy: 0.9984\n",
      "Epoch 00208: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2479 - dice_coef: 0.7521 - accuracy: 0.9984 - val_loss: 0.5568 - val_dice_coef: 0.4470 - val_accuracy: 0.9887\n",
      "Epoch 209/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2469 - dice_coef: 0.7531 - accuracy: 0.9984\n",
      "Epoch 00209: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2469 - dice_coef: 0.7531 - accuracy: 0.9984 - val_loss: 0.6140 - val_dice_coef: 0.3848 - val_accuracy: 0.9875\n",
      "Epoch 210/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2461 - dice_coef: 0.7538 - accuracy: 0.9984\n",
      "Epoch 00210: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2461 - dice_coef: 0.7538 - accuracy: 0.9984 - val_loss: 0.5605 - val_dice_coef: 0.4396 - val_accuracy: 0.9884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2459 - dice_coef: 0.7540 - accuracy: 0.9984\n",
      "Epoch 00211: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2459 - dice_coef: 0.7540 - accuracy: 0.9984 - val_loss: 0.5629 - val_dice_coef: 0.4404 - val_accuracy: 0.9882\n",
      "Epoch 212/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2453 - dice_coef: 0.7547 - accuracy: 0.9984\n",
      "Epoch 00212: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2453 - dice_coef: 0.7547 - accuracy: 0.9984 - val_loss: 0.5786 - val_dice_coef: 0.4216 - val_accuracy: 0.9882\n",
      "Epoch 213/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2448 - dice_coef: 0.7552 - accuracy: 0.9984\n",
      "Epoch 00213: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2448 - dice_coef: 0.7552 - accuracy: 0.9984 - val_loss: 0.5247 - val_dice_coef: 0.4787 - val_accuracy: 0.9886\n",
      "Epoch 214/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2444 - dice_coef: 0.7556 - accuracy: 0.9985\n",
      "Epoch 00214: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2444 - dice_coef: 0.7556 - accuracy: 0.9985 - val_loss: 0.5325 - val_dice_coef: 0.4671 - val_accuracy: 0.9886\n",
      "Epoch 215/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2435 - dice_coef: 0.7565 - accuracy: 0.9985\n",
      "Epoch 00215: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2435 - dice_coef: 0.7565 - accuracy: 0.9985 - val_loss: 0.5565 - val_dice_coef: 0.4452 - val_accuracy: 0.9886\n",
      "Epoch 216/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2433 - dice_coef: 0.7567 - accuracy: 0.9985\n",
      "Epoch 00216: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2433 - dice_coef: 0.7567 - accuracy: 0.9985 - val_loss: 0.5229 - val_dice_coef: 0.4805 - val_accuracy: 0.9890\n",
      "Epoch 217/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2427 - dice_coef: 0.7573 - accuracy: 0.9985\n",
      "Epoch 00217: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2427 - dice_coef: 0.7573 - accuracy: 0.9985 - val_loss: 0.5410 - val_dice_coef: 0.4563 - val_accuracy: 0.9892\n",
      "Epoch 218/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2418 - dice_coef: 0.7583 - accuracy: 0.9985\n",
      "Epoch 00218: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2418 - dice_coef: 0.7583 - accuracy: 0.9985 - val_loss: 0.5284 - val_dice_coef: 0.4700 - val_accuracy: 0.9895\n",
      "Epoch 219/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2412 - dice_coef: 0.7588 - accuracy: 0.9985\n",
      "Epoch 00219: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2412 - dice_coef: 0.7588 - accuracy: 0.9985 - val_loss: 0.5221 - val_dice_coef: 0.4805 - val_accuracy: 0.9886\n",
      "Epoch 220/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2411 - dice_coef: 0.7589 - accuracy: 0.9985\n",
      "Epoch 00220: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2411 - dice_coef: 0.7589 - accuracy: 0.9985 - val_loss: 0.5296 - val_dice_coef: 0.4735 - val_accuracy: 0.9888\n",
      "Epoch 221/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2404 - dice_coef: 0.7595 - accuracy: 0.9985\n",
      "Epoch 00221: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2404 - dice_coef: 0.7595 - accuracy: 0.9985 - val_loss: 0.5331 - val_dice_coef: 0.4713 - val_accuracy: 0.9891\n",
      "Epoch 222/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2399 - dice_coef: 0.7601 - accuracy: 0.9985\n",
      "Epoch 00222: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2399 - dice_coef: 0.7601 - accuracy: 0.9985 - val_loss: 0.5208 - val_dice_coef: 0.4735 - val_accuracy: 0.9891\n",
      "Epoch 223/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2388 - dice_coef: 0.7613 - accuracy: 0.9985\n",
      "Epoch 00223: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2388 - dice_coef: 0.7613 - accuracy: 0.9985 - val_loss: 0.5503 - val_dice_coef: 0.4471 - val_accuracy: 0.9885\n",
      "Epoch 224/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2389 - dice_coef: 0.7612 - accuracy: 0.9985\n",
      "Epoch 00224: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2389 - dice_coef: 0.7612 - accuracy: 0.9985 - val_loss: 0.5964 - val_dice_coef: 0.4021 - val_accuracy: 0.9884\n",
      "Epoch 225/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2377 - dice_coef: 0.7623 - accuracy: 0.9985\n",
      "Epoch 00225: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2377 - dice_coef: 0.7623 - accuracy: 0.9985 - val_loss: 0.5290 - val_dice_coef: 0.4693 - val_accuracy: 0.9884\n",
      "Epoch 226/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2373 - dice_coef: 0.7627 - accuracy: 0.9985\n",
      "Epoch 00226: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2373 - dice_coef: 0.7627 - accuracy: 0.9985 - val_loss: 0.5465 - val_dice_coef: 0.4516 - val_accuracy: 0.9876\n",
      "Epoch 227/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2367 - dice_coef: 0.7633 - accuracy: 0.9985\n",
      "Epoch 00227: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2367 - dice_coef: 0.7633 - accuracy: 0.9985 - val_loss: 0.5202 - val_dice_coef: 0.4769 - val_accuracy: 0.9886\n",
      "Epoch 228/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2362 - dice_coef: 0.7638 - accuracy: 0.9985\n",
      "Epoch 00228: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2362 - dice_coef: 0.7638 - accuracy: 0.9985 - val_loss: 0.5245 - val_dice_coef: 0.4759 - val_accuracy: 0.9885\n",
      "Epoch 229/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2355 - dice_coef: 0.7645 - accuracy: 0.9985\n",
      "Epoch 00229: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2355 - dice_coef: 0.7645 - accuracy: 0.9985 - val_loss: 0.5328 - val_dice_coef: 0.4654 - val_accuracy: 0.9886\n",
      "Epoch 230/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2354 - dice_coef: 0.7645 - accuracy: 0.9985\n",
      "Epoch 00230: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2354 - dice_coef: 0.7645 - accuracy: 0.9985 - val_loss: 0.5404 - val_dice_coef: 0.4624 - val_accuracy: 0.9887\n",
      "Epoch 231/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2348 - dice_coef: 0.7652 - accuracy: 0.9985\n",
      "Epoch 00231: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2348 - dice_coef: 0.7652 - accuracy: 0.9985 - val_loss: 0.5514 - val_dice_coef: 0.4486 - val_accuracy: 0.9881\n",
      "Epoch 232/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2339 - dice_coef: 0.7661 - accuracy: 0.9986\n",
      "Epoch 00232: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2339 - dice_coef: 0.7661 - accuracy: 0.9986 - val_loss: 0.5328 - val_dice_coef: 0.4694 - val_accuracy: 0.9886\n",
      "Epoch 233/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2334 - dice_coef: 0.7666 - accuracy: 0.9986\n",
      "Epoch 00233: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2334 - dice_coef: 0.7666 - accuracy: 0.9986 - val_loss: 0.5161 - val_dice_coef: 0.4885 - val_accuracy: 0.9891\n",
      "Epoch 234/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2328 - dice_coef: 0.7672 - accuracy: 0.9986\n",
      "Epoch 00234: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2328 - dice_coef: 0.7672 - accuracy: 0.9986 - val_loss: 0.5188 - val_dice_coef: 0.4840 - val_accuracy: 0.9889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2328 - dice_coef: 0.7673 - accuracy: 0.9985\n",
      "Epoch 00235: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2328 - dice_coef: 0.7673 - accuracy: 0.9985 - val_loss: 0.5259 - val_dice_coef: 0.4782 - val_accuracy: 0.9892\n",
      "Epoch 236/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2320 - dice_coef: 0.7679 - accuracy: 0.9985\n",
      "Epoch 00236: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2320 - dice_coef: 0.7679 - accuracy: 0.9985 - val_loss: 0.5137 - val_dice_coef: 0.4861 - val_accuracy: 0.9887\n",
      "Epoch 237/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2311 - dice_coef: 0.7689 - accuracy: 0.9986\n",
      "Epoch 00237: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2311 - dice_coef: 0.7689 - accuracy: 0.9986 - val_loss: 0.5589 - val_dice_coef: 0.4409 - val_accuracy: 0.9883\n",
      "Epoch 238/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2306 - dice_coef: 0.7694 - accuracy: 0.9986\n",
      "Epoch 00238: val_loss did not improve from 0.51133\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2306 - dice_coef: 0.7694 - accuracy: 0.9986 - val_loss: 0.5195 - val_dice_coef: 0.4817 - val_accuracy: 0.9888\n",
      "Epoch 239/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2298 - dice_coef: 0.7702 - accuracy: 0.9986\n",
      "Epoch 00239: val_loss improved from 0.51133 to 0.50489, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 455ms/step - loss: 0.2298 - dice_coef: 0.7702 - accuracy: 0.9986 - val_loss: 0.5049 - val_dice_coef: 0.4975 - val_accuracy: 0.9891\n",
      "Epoch 240/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2296 - dice_coef: 0.7703 - accuracy: 0.9986\n",
      "Epoch 00240: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2296 - dice_coef: 0.7703 - accuracy: 0.9986 - val_loss: 0.5067 - val_dice_coef: 0.4941 - val_accuracy: 0.9886\n",
      "Epoch 241/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2290 - dice_coef: 0.7710 - accuracy: 0.9986\n",
      "Epoch 00241: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2290 - dice_coef: 0.7710 - accuracy: 0.9986 - val_loss: 0.5639 - val_dice_coef: 0.4363 - val_accuracy: 0.9881\n",
      "Epoch 242/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2281 - dice_coef: 0.7719 - accuracy: 0.9986\n",
      "Epoch 00242: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2281 - dice_coef: 0.7719 - accuracy: 0.9986 - val_loss: 0.5670 - val_dice_coef: 0.4351 - val_accuracy: 0.9881\n",
      "Epoch 243/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2280 - dice_coef: 0.7720 - accuracy: 0.9986\n",
      "Epoch 00243: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2280 - dice_coef: 0.7720 - accuracy: 0.9986 - val_loss: 0.5308 - val_dice_coef: 0.4651 - val_accuracy: 0.9870\n",
      "Epoch 244/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2273 - dice_coef: 0.7728 - accuracy: 0.9986\n",
      "Epoch 00244: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2273 - dice_coef: 0.7728 - accuracy: 0.9986 - val_loss: 0.5212 - val_dice_coef: 0.4791 - val_accuracy: 0.9886\n",
      "Epoch 245/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2270 - dice_coef: 0.7730 - accuracy: 0.9986\n",
      "Epoch 00245: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2270 - dice_coef: 0.7730 - accuracy: 0.9986 - val_loss: 0.5712 - val_dice_coef: 0.4323 - val_accuracy: 0.9878\n",
      "Epoch 246/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2261 - dice_coef: 0.7739 - accuracy: 0.9986\n",
      "Epoch 00246: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2261 - dice_coef: 0.7739 - accuracy: 0.9986 - val_loss: 0.5480 - val_dice_coef: 0.4510 - val_accuracy: 0.9885\n",
      "Epoch 247/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2266 - dice_coef: 0.7734 - accuracy: 0.9986\n",
      "Epoch 00247: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2266 - dice_coef: 0.7734 - accuracy: 0.9986 - val_loss: 0.5137 - val_dice_coef: 0.4834 - val_accuracy: 0.9888\n",
      "Epoch 248/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2249 - dice_coef: 0.7751 - accuracy: 0.9986\n",
      "Epoch 00248: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2249 - dice_coef: 0.7751 - accuracy: 0.9986 - val_loss: 0.5195 - val_dice_coef: 0.4851 - val_accuracy: 0.9885\n",
      "Epoch 249/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2243 - dice_coef: 0.7757 - accuracy: 0.9986\n",
      "Epoch 00249: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2243 - dice_coef: 0.7757 - accuracy: 0.9986 - val_loss: 0.5513 - val_dice_coef: 0.4490 - val_accuracy: 0.9879\n",
      "Epoch 250/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2239 - dice_coef: 0.7761 - accuracy: 0.9986\n",
      "Epoch 00250: val_loss did not improve from 0.50489\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2239 - dice_coef: 0.7761 - accuracy: 0.9986 - val_loss: 0.5180 - val_dice_coef: 0.4830 - val_accuracy: 0.9872\n",
      "Epoch 251/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2235 - dice_coef: 0.7765 - accuracy: 0.9986\n",
      "Epoch 00251: val_loss improved from 0.50489 to 0.50366, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.2235 - dice_coef: 0.7765 - accuracy: 0.9986 - val_loss: 0.5037 - val_dice_coef: 0.4946 - val_accuracy: 0.9884\n",
      "Epoch 252/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2230 - dice_coef: 0.7770 - accuracy: 0.9986\n",
      "Epoch 00252: val_loss did not improve from 0.50366\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2230 - dice_coef: 0.7770 - accuracy: 0.9986 - val_loss: 0.5439 - val_dice_coef: 0.4562 - val_accuracy: 0.9885\n",
      "Epoch 253/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2229 - dice_coef: 0.7771 - accuracy: 0.9986\n",
      "Epoch 00253: val_loss did not improve from 0.50366\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2229 - dice_coef: 0.7771 - accuracy: 0.9986 - val_loss: 0.5416 - val_dice_coef: 0.4571 - val_accuracy: 0.9882\n",
      "Epoch 254/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2218 - dice_coef: 0.7782 - accuracy: 0.9986\n",
      "Epoch 00254: val_loss did not improve from 0.50366\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2218 - dice_coef: 0.7782 - accuracy: 0.9986 - val_loss: 0.5226 - val_dice_coef: 0.4805 - val_accuracy: 0.9892\n",
      "Epoch 255/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2210 - dice_coef: 0.7790 - accuracy: 0.9987\n",
      "Epoch 00255: val_loss improved from 0.50366 to 0.50317, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 454ms/step - loss: 0.2210 - dice_coef: 0.7790 - accuracy: 0.9987 - val_loss: 0.5032 - val_dice_coef: 0.4982 - val_accuracy: 0.9897\n",
      "Epoch 256/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2207 - dice_coef: 0.7793 - accuracy: 0.9987\n",
      "Epoch 00256: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2207 - dice_coef: 0.7793 - accuracy: 0.9987 - val_loss: 0.5359 - val_dice_coef: 0.4619 - val_accuracy: 0.9888\n",
      "Epoch 257/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2200 - dice_coef: 0.7800 - accuracy: 0.9987\n",
      "Epoch 00257: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2200 - dice_coef: 0.7800 - accuracy: 0.9987 - val_loss: 0.5125 - val_dice_coef: 0.4906 - val_accuracy: 0.9894\n",
      "Epoch 258/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - ETA: 0s - loss: 0.2199 - dice_coef: 0.7802 - accuracy: 0.9987\n",
      "Epoch 00258: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2199 - dice_coef: 0.7802 - accuracy: 0.9987 - val_loss: 0.5285 - val_dice_coef: 0.4748 - val_accuracy: 0.9885\n",
      "Epoch 259/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2192 - dice_coef: 0.7807 - accuracy: 0.9987\n",
      "Epoch 00259: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2192 - dice_coef: 0.7807 - accuracy: 0.9987 - val_loss: 0.5459 - val_dice_coef: 0.4533 - val_accuracy: 0.9873\n",
      "Epoch 260/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2188 - dice_coef: 0.7812 - accuracy: 0.9987\n",
      "Epoch 00260: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2188 - dice_coef: 0.7812 - accuracy: 0.9987 - val_loss: 0.5683 - val_dice_coef: 0.4323 - val_accuracy: 0.9880\n",
      "Epoch 261/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2181 - dice_coef: 0.7819 - accuracy: 0.9987\n",
      "Epoch 00261: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2181 - dice_coef: 0.7819 - accuracy: 0.9987 - val_loss: 0.5524 - val_dice_coef: 0.4462 - val_accuracy: 0.9881\n",
      "Epoch 262/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2172 - dice_coef: 0.7829 - accuracy: 0.9987\n",
      "Epoch 00262: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2172 - dice_coef: 0.7829 - accuracy: 0.9987 - val_loss: 0.5438 - val_dice_coef: 0.4565 - val_accuracy: 0.9882\n",
      "Epoch 263/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2172 - dice_coef: 0.7829 - accuracy: 0.9987\n",
      "Epoch 00263: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2172 - dice_coef: 0.7829 - accuracy: 0.9987 - val_loss: 0.5197 - val_dice_coef: 0.4811 - val_accuracy: 0.9869\n",
      "Epoch 264/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2167 - dice_coef: 0.7833 - accuracy: 0.9987\n",
      "Epoch 00264: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2167 - dice_coef: 0.7833 - accuracy: 0.9987 - val_loss: 0.5282 - val_dice_coef: 0.4765 - val_accuracy: 0.9881\n",
      "Epoch 265/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2158 - dice_coef: 0.7842 - accuracy: 0.9987\n",
      "Epoch 00265: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2158 - dice_coef: 0.7842 - accuracy: 0.9987 - val_loss: 0.5496 - val_dice_coef: 0.4523 - val_accuracy: 0.9873\n",
      "Epoch 266/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2154 - dice_coef: 0.7845 - accuracy: 0.9987\n",
      "Epoch 00266: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2154 - dice_coef: 0.7845 - accuracy: 0.9987 - val_loss: 0.5107 - val_dice_coef: 0.4877 - val_accuracy: 0.9886\n",
      "Epoch 267/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2147 - dice_coef: 0.7853 - accuracy: 0.9987\n",
      "Epoch 00267: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2147 - dice_coef: 0.7853 - accuracy: 0.9987 - val_loss: 0.5285 - val_dice_coef: 0.4738 - val_accuracy: 0.9884\n",
      "Epoch 268/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2144 - dice_coef: 0.7856 - accuracy: 0.9987\n",
      "Epoch 00268: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2144 - dice_coef: 0.7856 - accuracy: 0.9987 - val_loss: 0.5278 - val_dice_coef: 0.4730 - val_accuracy: 0.9883\n",
      "Epoch 269/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2138 - dice_coef: 0.7862 - accuracy: 0.9987\n",
      "Epoch 00269: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2138 - dice_coef: 0.7862 - accuracy: 0.9987 - val_loss: 0.5066 - val_dice_coef: 0.4935 - val_accuracy: 0.9887\n",
      "Epoch 270/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2131 - dice_coef: 0.7869 - accuracy: 0.9987\n",
      "Epoch 00270: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2131 - dice_coef: 0.7869 - accuracy: 0.9987 - val_loss: 0.5164 - val_dice_coef: 0.4856 - val_accuracy: 0.9886\n",
      "Epoch 271/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2124 - dice_coef: 0.7876 - accuracy: 0.9987\n",
      "Epoch 00271: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2124 - dice_coef: 0.7876 - accuracy: 0.9987 - val_loss: 0.5347 - val_dice_coef: 0.4717 - val_accuracy: 0.9882\n",
      "Epoch 272/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2123 - dice_coef: 0.7876 - accuracy: 0.9987\n",
      "Epoch 00272: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2123 - dice_coef: 0.7876 - accuracy: 0.9987 - val_loss: 0.5164 - val_dice_coef: 0.4796 - val_accuracy: 0.9887\n",
      "Epoch 273/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2117 - dice_coef: 0.7883 - accuracy: 0.9987\n",
      "Epoch 00273: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2117 - dice_coef: 0.7883 - accuracy: 0.9987 - val_loss: 0.5101 - val_dice_coef: 0.4887 - val_accuracy: 0.9883\n",
      "Epoch 274/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2109 - dice_coef: 0.7891 - accuracy: 0.9987\n",
      "Epoch 00274: val_loss did not improve from 0.50317\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2109 - dice_coef: 0.7891 - accuracy: 0.9987 - val_loss: 0.5565 - val_dice_coef: 0.4425 - val_accuracy: 0.9884\n",
      "Epoch 275/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2105 - dice_coef: 0.7895 - accuracy: 0.9987\n",
      "Epoch 00275: val_loss improved from 0.50317 to 0.49977, saving model to ventral.hdf5\n",
      "300/300 [==============================] - 136s 455ms/step - loss: 0.2105 - dice_coef: 0.7895 - accuracy: 0.9987 - val_loss: 0.4998 - val_dice_coef: 0.4976 - val_accuracy: 0.9885\n",
      "Epoch 276/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2098 - dice_coef: 0.7902 - accuracy: 0.9988\n",
      "Epoch 00276: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2098 - dice_coef: 0.7902 - accuracy: 0.9988 - val_loss: 0.5065 - val_dice_coef: 0.4950 - val_accuracy: 0.9879\n",
      "Epoch 277/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2098 - dice_coef: 0.7902 - accuracy: 0.9987\n",
      "Epoch 00277: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2098 - dice_coef: 0.7902 - accuracy: 0.9987 - val_loss: 0.5260 - val_dice_coef: 0.4722 - val_accuracy: 0.9882\n",
      "Epoch 278/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2092 - dice_coef: 0.7908 - accuracy: 0.9988\n",
      "Epoch 00278: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2092 - dice_coef: 0.7908 - accuracy: 0.9988 - val_loss: 0.5159 - val_dice_coef: 0.4898 - val_accuracy: 0.9884\n",
      "Epoch 279/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2085 - dice_coef: 0.7915 - accuracy: 0.9988\n",
      "Epoch 00279: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2085 - dice_coef: 0.7915 - accuracy: 0.9988 - val_loss: 0.5553 - val_dice_coef: 0.4469 - val_accuracy: 0.9887\n",
      "Epoch 280/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2081 - dice_coef: 0.7919 - accuracy: 0.9988\n",
      "Epoch 00280: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2081 - dice_coef: 0.7919 - accuracy: 0.9988 - val_loss: 0.5014 - val_dice_coef: 0.4993 - val_accuracy: 0.9886\n",
      "Epoch 281/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2077 - dice_coef: 0.7922 - accuracy: 0.9988\n",
      "Epoch 00281: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2077 - dice_coef: 0.7922 - accuracy: 0.9988 - val_loss: 0.5220 - val_dice_coef: 0.4739 - val_accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2069 - dice_coef: 0.7930 - accuracy: 0.9988\n",
      "Epoch 00282: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2069 - dice_coef: 0.7930 - accuracy: 0.9988 - val_loss: 0.5221 - val_dice_coef: 0.4792 - val_accuracy: 0.9888\n",
      "Epoch 283/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2066 - dice_coef: 0.7934 - accuracy: 0.9988\n",
      "Epoch 00283: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.2066 - dice_coef: 0.7934 - accuracy: 0.9988 - val_loss: 0.5462 - val_dice_coef: 0.4532 - val_accuracy: 0.9881\n",
      "Epoch 284/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2061 - dice_coef: 0.7938 - accuracy: 0.9988\n",
      "Epoch 00284: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2061 - dice_coef: 0.7938 - accuracy: 0.9988 - val_loss: 0.5286 - val_dice_coef: 0.4637 - val_accuracy: 0.9884\n",
      "Epoch 285/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2054 - dice_coef: 0.7946 - accuracy: 0.9988\n",
      "Epoch 00285: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2054 - dice_coef: 0.7946 - accuracy: 0.9988 - val_loss: 0.5291 - val_dice_coef: 0.4719 - val_accuracy: 0.9886\n",
      "Epoch 286/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2050 - dice_coef: 0.7950 - accuracy: 0.9988\n",
      "Epoch 00286: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2050 - dice_coef: 0.7950 - accuracy: 0.9988 - val_loss: 0.5356 - val_dice_coef: 0.4654 - val_accuracy: 0.9883\n",
      "Epoch 287/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2045 - dice_coef: 0.7954 - accuracy: 0.9988\n",
      "Epoch 00287: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2045 - dice_coef: 0.7954 - accuracy: 0.9988 - val_loss: 0.5247 - val_dice_coef: 0.4807 - val_accuracy: 0.9883\n",
      "Epoch 288/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2040 - dice_coef: 0.7960 - accuracy: 0.9988\n",
      "Epoch 00288: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2040 - dice_coef: 0.7960 - accuracy: 0.9988 - val_loss: 0.5183 - val_dice_coef: 0.4861 - val_accuracy: 0.9881\n",
      "Epoch 289/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2032 - dice_coef: 0.7967 - accuracy: 0.9988\n",
      "Epoch 00289: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2032 - dice_coef: 0.7967 - accuracy: 0.9988 - val_loss: 0.5307 - val_dice_coef: 0.4656 - val_accuracy: 0.9876\n",
      "Epoch 290/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2031 - dice_coef: 0.7969 - accuracy: 0.9988\n",
      "Epoch 00290: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2031 - dice_coef: 0.7969 - accuracy: 0.9988 - val_loss: 0.5398 - val_dice_coef: 0.4554 - val_accuracy: 0.9869\n",
      "Epoch 291/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2024 - dice_coef: 0.7976 - accuracy: 0.9988\n",
      "Epoch 00291: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2024 - dice_coef: 0.7976 - accuracy: 0.9988 - val_loss: 0.5298 - val_dice_coef: 0.4736 - val_accuracy: 0.9881\n",
      "Epoch 292/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2025 - dice_coef: 0.7975 - accuracy: 0.9988\n",
      "Epoch 00292: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2025 - dice_coef: 0.7975 - accuracy: 0.9988 - val_loss: 0.5269 - val_dice_coef: 0.4718 - val_accuracy: 0.9882\n",
      "Epoch 293/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2015 - dice_coef: 0.7985 - accuracy: 0.9988\n",
      "Epoch 00293: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 135s 452ms/step - loss: 0.2015 - dice_coef: 0.7985 - accuracy: 0.9988 - val_loss: 0.5183 - val_dice_coef: 0.4846 - val_accuracy: 0.9879\n",
      "Epoch 294/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2010 - dice_coef: 0.7990 - accuracy: 0.9988\n",
      "Epoch 00294: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2010 - dice_coef: 0.7990 - accuracy: 0.9988 - val_loss: 0.5016 - val_dice_coef: 0.4930 - val_accuracy: 0.9890\n",
      "Epoch 295/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2003 - dice_coef: 0.7997 - accuracy: 0.9988\n",
      "Epoch 00295: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2003 - dice_coef: 0.7997 - accuracy: 0.9988 - val_loss: 0.5076 - val_dice_coef: 0.4925 - val_accuracy: 0.9889\n",
      "Epoch 296/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2001 - dice_coef: 0.7998 - accuracy: 0.9988\n",
      "Epoch 00296: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.2001 - dice_coef: 0.7998 - accuracy: 0.9988 - val_loss: 0.5215 - val_dice_coef: 0.4761 - val_accuracy: 0.9889\n",
      "Epoch 297/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1997 - dice_coef: 0.8003 - accuracy: 0.9988\n",
      "Epoch 00297: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1997 - dice_coef: 0.8003 - accuracy: 0.9988 - val_loss: 0.5525 - val_dice_coef: 0.4525 - val_accuracy: 0.9880\n",
      "Epoch 298/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1986 - dice_coef: 0.8014 - accuracy: 0.9988\n",
      "Epoch 00298: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1986 - dice_coef: 0.8014 - accuracy: 0.9988 - val_loss: 0.5385 - val_dice_coef: 0.4586 - val_accuracy: 0.9870\n",
      "Epoch 299/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1983 - dice_coef: 0.8017 - accuracy: 0.9989\n",
      "Epoch 00299: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1983 - dice_coef: 0.8017 - accuracy: 0.9989 - val_loss: 0.5127 - val_dice_coef: 0.4828 - val_accuracy: 0.9880\n",
      "Epoch 300/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1981 - dice_coef: 0.8019 - accuracy: 0.9988\n",
      "Epoch 00300: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1981 - dice_coef: 0.8019 - accuracy: 0.9988 - val_loss: 0.5126 - val_dice_coef: 0.4878 - val_accuracy: 0.9876\n",
      "Epoch 301/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1973 - dice_coef: 0.8028 - accuracy: 0.9989\n",
      "Epoch 00301: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1973 - dice_coef: 0.8028 - accuracy: 0.9989 - val_loss: 0.5291 - val_dice_coef: 0.4717 - val_accuracy: 0.9882\n",
      "Epoch 302/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1973 - dice_coef: 0.8027 - accuracy: 0.9988\n",
      "Epoch 00302: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1973 - dice_coef: 0.8027 - accuracy: 0.9988 - val_loss: 0.5111 - val_dice_coef: 0.4918 - val_accuracy: 0.9882\n",
      "Epoch 303/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1967 - dice_coef: 0.8033 - accuracy: 0.9989\n",
      "Epoch 00303: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.1967 - dice_coef: 0.8033 - accuracy: 0.9989 - val_loss: 0.5190 - val_dice_coef: 0.4801 - val_accuracy: 0.9876\n",
      "Epoch 304/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1959 - dice_coef: 0.8040 - accuracy: 0.9989\n",
      "Epoch 00304: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1959 - dice_coef: 0.8040 - accuracy: 0.9989 - val_loss: 0.5362 - val_dice_coef: 0.4608 - val_accuracy: 0.9875\n",
      "Epoch 305/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1954 - dice_coef: 0.8046 - accuracy: 0.9989\n",
      "Epoch 00305: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1954 - dice_coef: 0.8046 - accuracy: 0.9989 - val_loss: 0.5463 - val_dice_coef: 0.4493 - val_accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1951 - dice_coef: 0.8049 - accuracy: 0.9989\n",
      "Epoch 00306: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1951 - dice_coef: 0.8049 - accuracy: 0.9989 - val_loss: 0.5383 - val_dice_coef: 0.4574 - val_accuracy: 0.9870\n",
      "Epoch 307/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1944 - dice_coef: 0.8057 - accuracy: 0.9989\n",
      "Epoch 00307: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1944 - dice_coef: 0.8057 - accuracy: 0.9989 - val_loss: 0.5016 - val_dice_coef: 0.4950 - val_accuracy: 0.9889\n",
      "Epoch 308/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1941 - dice_coef: 0.8058 - accuracy: 0.9989\n",
      "Epoch 00308: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 135s 452ms/step - loss: 0.1941 - dice_coef: 0.8058 - accuracy: 0.9989 - val_loss: 0.5279 - val_dice_coef: 0.4645 - val_accuracy: 0.9890\n",
      "Epoch 309/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1937 - dice_coef: 0.8063 - accuracy: 0.9989\n",
      "Epoch 00309: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1937 - dice_coef: 0.8063 - accuracy: 0.9989 - val_loss: 0.5001 - val_dice_coef: 0.5022 - val_accuracy: 0.9890\n",
      "Epoch 310/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1927 - dice_coef: 0.8073 - accuracy: 0.9989\n",
      "Epoch 00310: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.1927 - dice_coef: 0.8073 - accuracy: 0.9989 - val_loss: 0.5122 - val_dice_coef: 0.4864 - val_accuracy: 0.9886\n",
      "Epoch 311/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1927 - dice_coef: 0.8073 - accuracy: 0.9989\n",
      "Epoch 00311: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1927 - dice_coef: 0.8073 - accuracy: 0.9989 - val_loss: 0.5382 - val_dice_coef: 0.4592 - val_accuracy: 0.9887\n",
      "Epoch 312/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1920 - dice_coef: 0.8079 - accuracy: 0.9989\n",
      "Epoch 00312: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1920 - dice_coef: 0.8079 - accuracy: 0.9989 - val_loss: 0.5316 - val_dice_coef: 0.4672 - val_accuracy: 0.9879\n",
      "Epoch 313/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1916 - dice_coef: 0.8084 - accuracy: 0.9989\n",
      "Epoch 00313: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1916 - dice_coef: 0.8084 - accuracy: 0.9989 - val_loss: 0.5761 - val_dice_coef: 0.4193 - val_accuracy: 0.9883\n",
      "Epoch 314/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1911 - dice_coef: 0.8089 - accuracy: 0.9989\n",
      "Epoch 00314: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1911 - dice_coef: 0.8089 - accuracy: 0.9989 - val_loss: 0.5358 - val_dice_coef: 0.4602 - val_accuracy: 0.9878\n",
      "Epoch 315/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1909 - dice_coef: 0.8091 - accuracy: 0.9989\n",
      "Epoch 00315: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1909 - dice_coef: 0.8091 - accuracy: 0.9989 - val_loss: 0.5146 - val_dice_coef: 0.4895 - val_accuracy: 0.9881\n",
      "Epoch 316/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1902 - dice_coef: 0.8098 - accuracy: 0.9989\n",
      "Epoch 00316: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1902 - dice_coef: 0.8098 - accuracy: 0.9989 - val_loss: 0.5342 - val_dice_coef: 0.4643 - val_accuracy: 0.9870\n",
      "Epoch 317/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1898 - dice_coef: 0.8102 - accuracy: 0.9989\n",
      "Epoch 00317: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1898 - dice_coef: 0.8102 - accuracy: 0.9989 - val_loss: 0.5228 - val_dice_coef: 0.4717 - val_accuracy: 0.9884\n",
      "Epoch 318/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1891 - dice_coef: 0.8109 - accuracy: 0.9989\n",
      "Epoch 00318: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 453ms/step - loss: 0.1891 - dice_coef: 0.8109 - accuracy: 0.9989 - val_loss: 0.5690 - val_dice_coef: 0.4344 - val_accuracy: 0.9881\n",
      "Epoch 319/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1890 - dice_coef: 0.8110 - accuracy: 0.9989\n",
      "Epoch 00319: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1890 - dice_coef: 0.8110 - accuracy: 0.9989 - val_loss: 0.5926 - val_dice_coef: 0.4088 - val_accuracy: 0.9878\n",
      "Epoch 320/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1884 - dice_coef: 0.8116 - accuracy: 0.9989\n",
      "Epoch 00320: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 135s 452ms/step - loss: 0.1884 - dice_coef: 0.8116 - accuracy: 0.9989 - val_loss: 0.5312 - val_dice_coef: 0.4681 - val_accuracy: 0.9885\n",
      "Epoch 321/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1878 - dice_coef: 0.8122 - accuracy: 0.9989\n",
      "Epoch 00321: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1878 - dice_coef: 0.8122 - accuracy: 0.9989 - val_loss: 0.5605 - val_dice_coef: 0.4362 - val_accuracy: 0.9881\n",
      "Epoch 322/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1878 - dice_coef: 0.8121 - accuracy: 0.9989\n",
      "Epoch 00322: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1878 - dice_coef: 0.8121 - accuracy: 0.9989 - val_loss: 0.5300 - val_dice_coef: 0.4683 - val_accuracy: 0.9882\n",
      "Epoch 323/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1871 - dice_coef: 0.8128 - accuracy: 0.9989\n",
      "Epoch 00323: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1871 - dice_coef: 0.8128 - accuracy: 0.9989 - val_loss: 0.5582 - val_dice_coef: 0.4458 - val_accuracy: 0.9880\n",
      "Epoch 324/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1863 - dice_coef: 0.8137 - accuracy: 0.9989\n",
      "Epoch 00324: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1863 - dice_coef: 0.8137 - accuracy: 0.9989 - val_loss: 0.5710 - val_dice_coef: 0.4351 - val_accuracy: 0.9878\n",
      "Epoch 325/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1861 - dice_coef: 0.8138 - accuracy: 0.9989\n",
      "Epoch 00325: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.1861 - dice_coef: 0.8138 - accuracy: 0.9989 - val_loss: 0.6006 - val_dice_coef: 0.3981 - val_accuracy: 0.9874\n",
      "Epoch 326/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1858 - dice_coef: 0.8141 - accuracy: 0.9989\n",
      "Epoch 00326: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.1858 - dice_coef: 0.8141 - accuracy: 0.9989 - val_loss: 0.5377 - val_dice_coef: 0.4597 - val_accuracy: 0.9878\n",
      "Epoch 327/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1851 - dice_coef: 0.8149 - accuracy: 0.9989\n",
      "Epoch 00327: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 458ms/step - loss: 0.1851 - dice_coef: 0.8149 - accuracy: 0.9989 - val_loss: 0.5313 - val_dice_coef: 0.4713 - val_accuracy: 0.9883\n",
      "Epoch 328/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1846 - dice_coef: 0.8153 - accuracy: 0.9989\n",
      "Epoch 00328: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 457ms/step - loss: 0.1846 - dice_coef: 0.8153 - accuracy: 0.9989 - val_loss: 0.5179 - val_dice_coef: 0.4851 - val_accuracy: 0.9886\n",
      "Epoch 329/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1843 - dice_coef: 0.8156 - accuracy: 0.9989\n",
      "Epoch 00329: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 457ms/step - loss: 0.1843 - dice_coef: 0.8156 - accuracy: 0.9989 - val_loss: 0.5129 - val_dice_coef: 0.4857 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1839 - dice_coef: 0.8160 - accuracy: 0.9989\n",
      "Epoch 00330: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 457ms/step - loss: 0.1839 - dice_coef: 0.8160 - accuracy: 0.9989 - val_loss: 0.5051 - val_dice_coef: 0.4991 - val_accuracy: 0.9893\n",
      "Epoch 331/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1831 - dice_coef: 0.8169 - accuracy: 0.9990\n",
      "Epoch 00331: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.1831 - dice_coef: 0.8169 - accuracy: 0.9990 - val_loss: 0.5166 - val_dice_coef: 0.4829 - val_accuracy: 0.9888\n",
      "Epoch 332/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1828 - dice_coef: 0.8172 - accuracy: 0.9990\n",
      "Epoch 00332: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 457ms/step - loss: 0.1828 - dice_coef: 0.8172 - accuracy: 0.9990 - val_loss: 0.5108 - val_dice_coef: 0.4937 - val_accuracy: 0.9882\n",
      "Epoch 333/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1822 - dice_coef: 0.8178 - accuracy: 0.9990\n",
      "Epoch 00333: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 457ms/step - loss: 0.1822 - dice_coef: 0.8178 - accuracy: 0.9990 - val_loss: 0.5061 - val_dice_coef: 0.4933 - val_accuracy: 0.9885\n",
      "Epoch 334/400\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1820 - dice_coef: 0.8180 - accuracy: 0.9990\n",
      "Epoch 00334: val_loss did not improve from 0.49977\n",
      "300/300 [==============================] - 137s 457ms/step - loss: 0.1820 - dice_coef: 0.8180 - accuracy: 0.9990 - val_loss: 0.5235 - val_dice_coef: 0.4764 - val_accuracy: 0.9888\n",
      "Epoch 335/400\n",
      "213/300 [====================>.........] - ETA: 39s - loss: 0.1813 - dice_coef: 0.8187 - accuracy: 0.9990"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7d592abd7be6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-04\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcooldown\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Try to start your training with x steps per epoch with y epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1829\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = unet(input_size = (256,256,3))\n",
    "model_checkpoint = ModelCheckpoint('ventral.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",verbose = 1,mode='min',patience=70)\n",
    "reduce_lr =  ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 10,verbose = 0, mode = \"auto\", epsilon = 1e-04, cooldown = 0,min_lr = 1e-5)\n",
    "model.fit_generator(train_generator,steps_per_epoch=iterations_per_epoch,epochs=epochs,callbacks=[model_checkpoint,early_stopping,reduce_lr],validation_data=val_datagen.flow(X_test, Y_test, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "# Create side by side png\n",
    "i=0\n",
    "for filepath in os.listdir('../data/test_images/ventral_samples_R0004'):\n",
    "    image = Image.open('../data/test_images/ventral_samples_R0004/'+filepath)\n",
    "    image = image.resize((256, 256))\n",
    "    # convert image to numpy array\n",
    "    data = np.asarray(image)\n",
    "    data = data/255.\n",
    "    arr = (model.predict(data.reshape(1,256,256,3))[0]).reshape(256,256)\n",
    "    mask = Image.fromarray((arr*255))\n",
    "    new_im = Image.new('RGB', (512, 256))\n",
    "    new_im.paste(mask, (0,0))\n",
    "    new_im.paste(image,(256,0))\n",
    "    new_im.save('vid/%d.png'%(i))\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
